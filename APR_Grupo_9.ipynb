{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUehXgCyIRdq"
   },
   "source": [
    "# Actividad - Proyecto práctico\n",
    "\n",
    "\n",
    "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
    "*   Alumno 1: Granizo, Mateo\n",
    "*   Alumno 2: Maiolo, Pablo\n",
    "*   Alumno 3: Miglino, Diego\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwpYlnjWJhS9"
   },
   "source": [
    "---\n",
    "## **PARTE 1** - Instalación y requisitos previos\n",
    "\n",
    "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
    "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
    "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
    "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
    "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU2BPrK2JkP0"
   },
   "source": [
    "---\n",
    "### 1.1. Preparar enviroment (solo local)\n",
    "\n",
    "\n",
    "\n",
    "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
    "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
    "2. Instalar Anaconda\n",
    "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
    "\n",
    "\n",
    "```\n",
    "conda create --name miar_rl python=3.8\n",
    "conda activate miar_rl\n",
    "cd \"PATH_TO_FOLDER\"\n",
    "conda install git\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "\n",
    "4. Abrir la notebook con *jupyter-notebook*.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "jupyter-notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-kixNPiJqTc"
   },
   "source": [
    "---\n",
    "### 1.2. Localizar entorno de trabajo: Google colab o local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_YDFwZ-JscI",
    "outputId": "01a99aa0-3d4e-4cd1-b1bc-309aef65070a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
    "mount='/content/gdrive'\n",
    "drive_root = mount + \"/My Drive/08_MIAR/actividades/TP_Grupal\"\n",
    "mount='./'\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dp_a1iBJ0tf"
   },
   "source": [
    "---\n",
    "### 1.3. Montar carpeta de datos local (solo Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6n7MIefJ21i",
    "outputId": "9a6fc610-9fb0-4f63-8562-46754d7d75fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en el directorio: \n",
      "['.git', '.ipynb_checkpoints', 'anaconda_projects', 'apr_g9_dqn_SpaceInvaders-v0_log.json', 'APR_Grupo_9.ipynb', 'best_model_weights.h5f.data-00000-of-00001', 'best_model_weights.h5f.index', 'checkpoint', 'grafico_recompensas.png', 'mejor_ejecucion.txt', 'README.md', 'SpaceInvaders_ReinforcementLearning', 'test_rewards.npy', 'video']\n"
     ]
    }
   ],
   "source": [
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    # Mount the Google Drive at mount\n",
    "    print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "    drive.mount(mount)\n",
    "\n",
    "    # Create drive_root if it doesn't exist\n",
    "    create_drive_root = True\n",
    "    if create_drive_root:\n",
    "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "      os.makedirs(drive_root, exist_ok=True)\n",
    "\n",
    "    # Change to the directory\n",
    "    print(\"\\nColab: Changing directory to \", drive_root)\n",
    "    %cd $drive_root\n",
    "# Verify we're in the correct working directory\n",
    "%pwd\n",
    "print(\"Archivos en el directorio: \")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1ZSL5bpJ560"
   },
   "source": [
    "---\n",
    "### 1.4. Instalar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UbVRjvHCJ8UF",
    "outputId": "fe539761-ae1b-4e9f-95de-9a3cfa9ae8bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.24.4)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/Kojoley/atari-py.git\n",
      "  Cloning https://github.com/Kojoley/atari-py.git to c:\\users\\dmigl\\appdata\\local\\temp\\pip-req-build-r02cc9bg\n",
      "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from atari-py==1.2.2) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git 'C:\\Users\\dmigl\\AppData\\Local\\Temp\\pip-req-build-r02cc9bg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet==1.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet==1.5.0) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: h5py==3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from h5py==3.1.0) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras-rl2==1.0.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from keras-rl2==1.0.5) (2.5.3)\n",
      "Collecting numpy~=1.19.2 (from tensorflow->keras-rl2==1.0.5)\n",
      "  Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.2.2)\n",
      "Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Successfully installed numpy-1.19.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras==2.2.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.10.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (6.0.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (3.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow==2.5.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.3) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (3.2.2)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.7.4.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Requirement already satisfied: agents==1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (2.5.3)\n",
      "Requirement already satisfied: gym in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (0.17.3)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (0.18.14)\n",
      "Requirement already satisfied: scipy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.6.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from ruamel.yaml->agents==1.4.0) (0.2.8)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.34.1)\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym->agents==1.4.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ejecutar solo la primera vez..\n",
    "\n",
    "if IN_COLAB:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install tensorflow==2.12\n",
    "else:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install pyglet==1.5.0\n",
    "  %pip install h5py==3.1.0\n",
    "  %pip install Pillow==9.5.0\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install Keras==2.2.4\n",
    "  %pip install tensorflow==2.5.3\n",
    "  %pip install torch==2.0.1\n",
    "  %pip install agents==1.4.0\n",
    "  %pip install matplotlib==3.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hzP_5ZuGb2X"
   },
   "source": [
    "---\n",
    "## **PARTE 2**. Enunciado\n",
    "\n",
    "Consideraciones a tener en cuenta:\n",
    "\n",
    "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
    "\n",
    "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
    "\n",
    "Este proyecto práctico consta de tres partes:\n",
    "\n",
    "1.   Implementar la red neuronal que se usará en la solución\n",
    "2.   Implementar las distintas piezas de la solución DQN\n",
    "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
    "\n",
    "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
    "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
    "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
    "* Cada alumno deberá de subir la solución de forma individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_b3mzw8IzJP"
   },
   "source": [
    "---\n",
    "## **PARTE 3**. Desarrollo y preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duPmUNOVGb2a"
   },
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j3eRhgI-Gb2a"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4jgQjzoGb2a"
   },
   "source": [
    "#### Configuración base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwOE6I_KGb2a",
    "outputId": "941f9c3a-e542-42e6-bd55-a097f9b71828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de acciones disponibles: 6\n",
      "Formato de las observaciones: Box(0, 255, (210, 160, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "env_name = 'SpaceInvaders-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "print(\"Numero de acciones disponibles: \" + str(nb_actions))\n",
    "print(\"Formato de las observaciones: \" + str(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9jGEZUcpGb2a"
   },
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class SaveBestRewardCallback(Callback):\n",
    "    def __init__(self, env,\n",
    "                 filename='best_model.h5f',\n",
    "                 test_episodes=3,\n",
    "                 test_interval=50):\n",
    "        self.env = env\n",
    "        self.filename = filename\n",
    "        self.test_episodes = test_episodes\n",
    "        self.test_interval = test_interval\n",
    "        self.best_reward = -np.inf\n",
    "        self.steps_since_last_eval = 0\n",
    "\n",
    "    def on_step_end(self, step, logs=None):\n",
    "        self.steps_since_last_eval += 1\n",
    "\n",
    "        if self.steps_since_last_eval >= self.test_interval:\n",
    "            self.steps_since_last_eval = 0\n",
    "\n",
    "            # --- congelar contador ---\n",
    "            saved_step = self.model.step\n",
    "\n",
    "            # --- evaluación ---\n",
    "            history = self.model.test(\n",
    "                self.env,\n",
    "                nb_episodes=self.test_episodes,\n",
    "                visualize=False,\n",
    "                verbose=0\n",
    "            )\n",
    "            avg_reward = np.mean(history.history['episode_reward'])\n",
    "\n",
    "            # --- restaurar contador ---\n",
    "            self.model.step = saved_step\n",
    "\n",
    "            print(f\"\\n>>> Evaluando step {saved_step} -> avg reward: {avg_reward:.2f} -> {history.history['episode_reward']}\")\n",
    "\n",
    "            if avg_reward > self.best_reward:\n",
    "                self.best_reward = avg_reward\n",
    "                self.model.save_weights(self.filename, overwrite=True)\n",
    "                print(f\">>> Nuevo récord: {avg_reward:.2f}, pesos guardados en {self.filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de TensorFlow: 2.5.3\n",
      "[]\n",
      "No se detectó GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Versión de TensorFlow:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"GPU detectada:\", gpus[0])\n",
    "else:\n",
    "    print(\"No se detectó GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yitXTADGb2b"
   },
   "source": [
    "1. Implementación de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "(4, 84, 84)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# modelo mas complejo - usar este\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "print(K.image_data_format())\n",
    "print(input_shape)\n",
    "if K.image_data_format() == 'channels_last':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_data_format() == 'channels_first':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4), activation='relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nb_actions, activation='linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB9-_5HPGb2b"
   },
   "source": [
    "2. Implementación de la solución DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "foSlxWH1Gb2b"
   },
   "outputs": [],
   "source": [
    "# memoria para almacenar la experiencia del agente\n",
    "memory = SequentialMemory(limit=100000, window_length=WINDOW_LENGTH)\n",
    "\n",
    "# processor\n",
    "processor = AtariProcessor()\n",
    "\n",
    "# policy que el agente va a seguir\n",
    "#policy = BoltzmannQPolicy()\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
    "                              value_max=1.0, value_min=0.05, value_test=.05,\n",
    "                              nb_steps=50000)\n",
    "\n",
    "# definicion del agente\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
    "               memory=memory, processor=processor,\n",
    "               nb_steps_warmup=8000, gamma=.99,\n",
    "               target_model_update=4000,\n",
    "               train_interval=4)\n",
    "\n",
    "# compilacion del agente\n",
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 12/500 [..............................] - ETA: 2s - reward: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - ale.lives: 2.310\n",
      "\n",
      "Interval 2 (500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 3 (1000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 4 (1500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - ale.lives: 1.776\n",
      "\n",
      "Interval 5 (2000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0140\n",
      "Interval 6 (2500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0020\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - ale.lives: 1.206\n",
      "\n",
      "Interval 7 (3000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - ale.lives: 2.072\n",
      "\n",
      "Interval 8 (3500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.268\n",
      "\n",
      "Interval 9 (4000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 10 (4500 steps performed)\n",
      "486/500 [============================>.] - ETA: 0s - reward: 0.0123\n",
      ">>> Evaluando step 4999 -> avg reward: 19.25 -> [18.0, 18.0, 23.0, 18.0]\n",
      ">>> Nuevo récord: 19.25, pesos guardados en best_model_weights.h5f\n",
      "500/500 [==============================] - 15s 30ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - ale.lives: 2.640\n",
      "\n",
      "Interval 11 (5000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - ale.lives: 2.450\n",
      "\n",
      "Interval 12 (5500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 13 (6000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.256\n",
      "\n",
      "Interval 14 (6500 steps performed)\n",
      "500/500 [==============================] - 3s 7ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 1.942\n",
      "\n",
      "Interval 15 (7000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 16 (7500 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.022\n",
      "\n",
      "Interval 17 (8000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0300\n",
      "Interval 18 (8500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 19 (9000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 20 (9500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0181\n",
      ">>> Evaluando step 9999 -> avg reward: 20.50 -> [18.0, 18.0, 23.0, 23.0]\n",
      ">>> Nuevo récord: 20.50, pesos guardados en best_model_weights.h5f\n",
      "500/500 [==============================] - 19s 38ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 21 (10000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.488\n",
      "\n",
      "Interval 22 (10500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 23 (11000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.204\n",
      "\n",
      "Interval 24 (11500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.856\n",
      "\n",
      "Interval 25 (12000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 26 (12500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0320\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.342\n",
      "\n",
      "Interval 27 (13000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "Interval 28 (13500 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.038\n",
      "\n",
      "Interval 29 (14000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.764\n",
      "\n",
      "Interval 30 (14500 steps performed)\n",
      "490/500 [============================>.] - ETA: 0s - reward: 0.0286\n",
      ">>> Evaluando step 14999 -> avg reward: 19.25 -> [18.0, 18.0, 23.0, 18.0]\n",
      "500/500 [==============================] - 15s 30ms/step - reward: 0.0280\n",
      "Interval 31 (15000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - ale.lives: 2.460\n",
      "\n",
      "Interval 32 (15500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0120\n",
      "Interval 33 (16000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.228\n",
      "\n",
      "Interval 34 (16500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.884\n",
      "\n",
      "Interval 35 (17000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 36 (17500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.370\n",
      "\n",
      "Interval 37 (18000 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - ale.lives: 2.082\n",
      "\n",
      "Interval 38 (18500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.640\n",
      "\n",
      "Interval 39 (19000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0340\n",
      "Interval 40 (19500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0223\n",
      ">>> Evaluando step 19999 -> avg reward: 21.75 -> [18.0, 23.0, 23.0, 23.0]\n",
      ">>> Nuevo récord: 21.75, pesos guardados en best_model_weights.h5f\n",
      "500/500 [==============================] - 18s 37ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 41 (20000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0340\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - ale.lives: 2.496\n",
      "\n",
      "Interval 42 (20500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 43 (21000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 44 (21500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 45 (22000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 46 (22500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0120\n",
      "Interval 47 (23000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.474\n",
      "\n",
      "Interval 48 (23500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.086\n",
      "\n",
      "Interval 49 (24000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 1.810\n",
      "\n",
      "Interval 50 (24500 steps performed)\n",
      "489/500 [============================>.] - ETA: 0s - reward: 0.0327\n",
      ">>> Evaluando step 24999 -> avg reward: 18.50 -> [18.0, 18.0, 18.0, 20.0]\n",
      "500/500 [==============================] - 14s 27ms/step - reward: 0.0320\n",
      "Interval 51 (25000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - ale.lives: 2.482\n",
      "\n",
      "Interval 52 (25500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.060\n",
      "\n",
      "Interval 53 (26000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.730\n",
      "\n",
      "Interval 54 (26500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 55 (27000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.206\n",
      "\n",
      "Interval 56 (27500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.896\n",
      "\n",
      "Interval 57 (28000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0260\n",
      "Interval 58 (28500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.114\n",
      "\n",
      "Interval 59 (29000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "Interval 60 (29500 steps performed)\n",
      "490/500 [============================>.] - ETA: 0s - reward: 0.0286\n",
      ">>> Evaluando step 29999 -> avg reward: 19.25 -> [23.0, 18.0, 18.0, 18.0]\n",
      "500/500 [==============================] - 16s 32ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - ale.lives: 2.342\n",
      "\n",
      "Interval 61 (30000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - ale.lives: 2.524\n",
      "\n",
      "Interval 62 (30500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - ale.lives: 2.286\n",
      "\n",
      "Interval 63 (31000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 2.008\n",
      "\n",
      "Interval 64 (31500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0240\n",
      "Interval 65 (32000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.408\n",
      "\n",
      "Interval 66 (32500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 67 (33000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.158\n",
      "\n",
      "Interval 68 (33500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 1.860\n",
      "\n",
      "Interval 69 (34000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 70 (34500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0282\n",
      ">>> Evaluando step 34999 -> avg reward: 18.00 -> [18.0, 18.0, 18.0, 18.0]\n",
      "500/500 [==============================] - 14s 28ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.286\n",
      "\n",
      "Interval 71 (35000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - ale.lives: 2.490\n",
      "\n",
      "Interval 72 (35500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 73 (36000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 74 (36500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 27.000 [27.000, 27.000] - ale.lives: 2.406\n",
      "\n",
      "Interval 75 (37000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 76 (37500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 77 (38000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 27.000 [27.000, 27.000] - ale.lives: 2.412\n",
      "\n",
      "Interval 78 (38500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.082\n",
      "\n",
      "Interval 79 (39000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "Interval 80 (39500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0120\n",
      ">>> Evaluando step 39999 -> avg reward: 19.75 -> [18.0, 18.0, 23.0, 20.0]\n",
      "500/500 [==============================] - 16s 32ms/step - reward: 0.0120\n",
      "Interval 81 (40000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - ale.lives: 2.466\n",
      "\n",
      "Interval 82 (40500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 83 (41000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.224\n",
      "\n",
      "Interval 84 (41500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - ale.lives: 1.956\n",
      "\n",
      "Interval 85 (42000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0300\n",
      "Interval 86 (42500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.362\n",
      "\n",
      "Interval 87 (43000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.072\n",
      "\n",
      "Interval 88 (43500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.660\n",
      "\n",
      "Interval 89 (44000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0340\n",
      "Interval 90 (44500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0221\n",
      ">>> Evaluando step 44999 -> avg reward: 24.25 -> [27.0, 24.0, 23.0, 23.0]\n",
      ">>> Nuevo récord: 24.25, pesos guardados en best_model_weights.h5f\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 91 (45000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - ale.lives: 2.474\n",
      "\n",
      "Interval 92 (45500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.056\n",
      "\n",
      "Interval 93 (46000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 94 (46500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.666\n",
      "\n",
      "Interval 95 (47000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "Interval 96 (47500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.106\n",
      "\n",
      "Interval 97 (48000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 98 (48500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 99 (49000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.786\n",
      "\n",
      "Interval 100 (49500 steps performed)\n",
      "487/500 [============================>.] - ETA: 0s - reward: 0.0267\n",
      ">>> Evaluando step 49999 -> avg reward: 21.00 -> [21.0, 18.0, 19.0, 26.0]\n",
      "500/500 [==============================] - 17s 34ms/step - reward: 0.0260\n",
      "Interval 101 (50000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - ale.lives: 2.482\n",
      "\n",
      "Interval 102 (50500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.054\n",
      "\n",
      "Interval 103 (51000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 104 (51500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.610\n",
      "\n",
      "Interval 105 (52000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 106 (52500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.382\n",
      "\n",
      "Interval 107 (53000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.056\n",
      "\n",
      "Interval 108 (53500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.654\n",
      "\n",
      "Interval 109 (54000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0300\n",
      "Interval 110 (54500 steps performed)\n",
      "489/500 [============================>.] - ETA: 0s - reward: 0.0143\n",
      ">>> Evaluando step 54999 -> avg reward: 21.75 -> [18.0, 23.0, 23.0, 23.0]\n",
      "500/500 [==============================] - 19s 39ms/step - reward: 0.0140\n",
      "Interval 111 (55000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - ale.lives: 2.456\n",
      "\n",
      "Interval 112 (55500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 113 (56000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.232\n",
      "\n",
      "Interval 114 (56500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - ale.lives: 1.952\n",
      "\n",
      "Interval 115 (57000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 116 (57500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - ale.lives: 2.428\n",
      "\n",
      "Interval 117 (58000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 118 (58500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.660\n",
      "\n",
      "Interval 119 (59000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 120 (59500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0142\n",
      ">>> Evaluando step 59999 -> avg reward: 15.50 -> [18.0, 13.0, 18.0, 13.0]\n",
      "500/500 [==============================] - 12s 25ms/step - reward: 0.0140\n",
      "Interval 121 (60000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - ale.lives: 2.508\n",
      "\n",
      "Interval 122 (60500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - ale.lives: 2.284\n",
      "\n",
      "Interval 123 (61000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 124 (61500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.014\n",
      "\n",
      "Interval 125 (62000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.696\n",
      "\n",
      "Interval 126 (62500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 127 (63000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.174\n",
      "\n",
      "Interval 128 (63500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0160\n",
      "Interval 129 (64000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 130 (64500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0222\n",
      ">>> Evaluando step 64999 -> avg reward: 20.50 -> [18.0, 23.0, 23.0, 18.0]\n",
      "500/500 [==============================] - 18s 36ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 131 (65000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - ale.lives: 2.462\n",
      "\n",
      "Interval 132 (65500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.086\n",
      "\n",
      "Interval 133 (66000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 1.830\n",
      "\n",
      "Interval 134 (66500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0320\n",
      "Interval 135 (67000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.210\n",
      "\n",
      "Interval 136 (67500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.904\n",
      "\n",
      "Interval 137 (68000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "Interval 138 (68500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.054\n",
      "\n",
      "Interval 139 (69000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 140 (69500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0263\n",
      ">>> Evaluando step 69999 -> avg reward: 16.75 -> [18.0, 13.0, 18.0, 18.0]\n",
      "500/500 [==============================] - 14s 27ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 141 (70000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0340\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - ale.lives: 2.492\n",
      "\n",
      "Interval 142 (70500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 143 (71000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 144 (71500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 145 (72000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 146 (72500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 147 (73000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0340\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.478\n",
      "\n",
      "Interval 148 (73500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - ale.lives: 2.160\n",
      "\n",
      "Interval 149 (74000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.748\n",
      "\n",
      "Interval 150 (74500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0323\n",
      ">>> Evaluando step 74999 -> avg reward: 20.75 -> [17.0, 25.0, 18.0, 23.0]\n",
      "500/500 [==============================] - 19s 38ms/step - reward: 0.0320\n",
      "Interval 151 (75000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - ale.lives: 2.460\n",
      "\n",
      "Interval 152 (75500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 153 (76000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 154 (76500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.618\n",
      "\n",
      "Interval 155 (77000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 156 (77500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.414\n",
      "\n",
      "Interval 157 (78000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.082\n",
      "\n",
      "Interval 158 (78500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "Interval 159 (79000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.454\n",
      "\n",
      "Interval 160 (79500 steps performed)\n",
      "491/500 [============================>.] - ETA: 0s - reward: 0.0265\n",
      ">>> Evaluando step 79999 -> avg reward: 20.50 -> [23.0, 23.0, 13.0, 23.0]\n",
      "500/500 [==============================] - 19s 37ms/step - reward: 0.0260\n",
      "Interval 161 (80000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - ale.lives: 2.482\n",
      "\n",
      "Interval 162 (80500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "Interval 163 (81000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - ale.lives: 2.218\n",
      "\n",
      "Interval 164 (81500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.956\n",
      "\n",
      "Interval 165 (82000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 166 (82500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.038\n",
      "\n",
      "Interval 167 (83000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 168 (83500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 169 (84000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.226\n",
      "\n",
      "Interval 170 (84500 steps performed)\n",
      "491/500 [============================>.] - ETA: 0s - reward: 0.0224\n",
      ">>> Evaluando step 84999 -> avg reward: 19.75 -> [25.0, 18.0, 18.0, 18.0]\n",
      "500/500 [==============================] - 17s 34ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.926\n",
      "\n",
      "Interval 171 (85000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.444\n",
      "\n",
      "Interval 172 (85500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 173 (86000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.226\n",
      "\n",
      "Interval 174 (86500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.872\n",
      "\n",
      "Interval 175 (87000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 176 (87500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.324\n",
      "\n",
      "Interval 177 (88000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.002\n",
      "\n",
      "Interval 178 (88500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 179 (89000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "Interval 180 (89500 steps performed)\n",
      "490/500 [============================>.] - ETA: 0s - reward: 0.0143\n",
      ">>> Evaluando step 89999 -> avg reward: 19.75 -> [20.0, 18.0, 23.0, 18.0]\n",
      "500/500 [==============================] - 16s 32ms/step - reward: 0.0140\n",
      "Interval 181 (90000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.490\n",
      "\n",
      "Interval 182 (90500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.084\n",
      "\n",
      "Interval 183 (91000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0180\n",
      "Interval 184 (91500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - ale.lives: 1.626\n",
      "\n",
      "Interval 185 (92000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0280\n",
      "Interval 186 (92500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.392\n",
      "\n",
      "Interval 187 (93000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 2.076\n",
      "\n",
      "Interval 188 (93500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0200\n",
      "Interval 189 (94000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.374\n",
      "\n",
      "Interval 190 (94500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0283\n",
      ">>> Evaluando step 94999 -> avg reward: 20.50 -> [18.0, 18.0, 23.0, 23.0]\n",
      "500/500 [==============================] - 16s 33ms/step - reward: 0.0280\n",
      "Interval 191 (95000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - ale.lives: 2.446\n",
      "\n",
      "Interval 192 (95500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 193 (96000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.236\n",
      "\n",
      "Interval 194 (96500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0160\n",
      "Interval 195 (97000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 1.878\n",
      "\n",
      "Interval 196 (97500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - ale.lives: 1.632\n",
      "\n",
      "Interval 197 (98000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0300\n",
      "Interval 198 (98500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0120\n",
      "Interval 199 (99000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - ale.lives: 2.270\n",
      "\n",
      "Interval 200 (99500 steps performed)\n",
      "491/500 [============================>.] - ETA: 0s - reward: 0.0244\n",
      ">>> Evaluando step 99999 -> avg reward: 20.25 -> [18.0, 25.0, 18.0, 20.0]\n",
      "500/500 [==============================] - 16s 33ms/step - reward: 0.0240\n",
      "done, took 715.204 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236680c1c10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenamiento del agente\n",
    "weights_filename = 'apr_g9_dqn_{}_weights.h5f'.format(env_name)\n",
    "checkpoint_weights_filename = 'apr_g9_dqn_' + env_name + '_weights_{step}.h5f'\n",
    "log_filename = 'apr_g9_dqn_{}_log.json'.format(env_name)\n",
    "callbacks = [\n",
    "            ModelIntervalCheckpoint(checkpoint_weights_filename, interval=25000),\n",
    "            FileLogger(log_filename, interval=1000),\n",
    "            SaveBestRewardCallback(env, filename='best_model_weights.h5f', test_episodes=4, test_episodes=5000)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=100000, log_interval=500, visualize=False)\n",
    "\n",
    "# se graban los pesos finales luego de finalizar el entrenamiento\n",
    "#dqn.save_weights('apr_g9_dqn_{}_weights.h5f'.format(env_name), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OHYryKd1Gb2b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 30 episodes ...\n",
      "Episode 1: reward: 17.000, steps: 700\n",
      "Episode 2: reward: 18.000, steps: 694\n",
      "Episode 3: reward: 23.000, steps: 1138\n",
      "Episode 4: reward: 23.000, steps: 1148\n",
      "Episode 5: reward: 18.000, steps: 706\n",
      "Episode 6: reward: 20.000, steps: 720\n",
      "Episode 7: reward: 27.000, steps: 1520\n",
      "Episode 8: reward: 18.000, steps: 701\n",
      "Episode 9: reward: 18.000, steps: 712\n",
      "Episode 10: reward: 18.000, steps: 710\n",
      "Episode 11: reward: 18.000, steps: 695\n",
      "Episode 12: reward: 18.000, steps: 729\n",
      "Episode 13: reward: 13.000, steps: 600\n",
      "Episode 14: reward: 17.000, steps: 699\n",
      "Episode 15: reward: 18.000, steps: 705\n",
      "Episode 16: reward: 23.000, steps: 1132\n",
      "Episode 17: reward: 18.000, steps: 688\n",
      "Episode 18: reward: 23.000, steps: 1149\n",
      "Episode 19: reward: 18.000, steps: 707\n",
      "Episode 20: reward: 18.000, steps: 704\n",
      "Episode 21: reward: 18.000, steps: 712\n",
      "Episode 22: reward: 23.000, steps: 1145\n",
      "Episode 23: reward: 19.000, steps: 723\n",
      "Episode 24: reward: 23.000, steps: 1138\n",
      "Episode 25: reward: 18.000, steps: 698\n",
      "Episode 26: reward: 13.000, steps: 598\n",
      "Episode 27: reward: 18.000, steps: 704\n",
      "Episode 28: reward: 18.000, steps: 713\n",
      "Episode 29: reward: 23.000, steps: 1149\n",
      "Episode 30: reward: 23.000, steps: 1157\n",
      "\n",
      "Mejor Episodio 7 con Recompensa = 27.0\n",
      "Testing for 1 episodes ...\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# correr episodio con video\u001b[39;00m\n\u001b[0;32m     24\u001b[0m video_env \u001b[38;5;241m=\u001b[39m Monitor(gym\u001b[38;5;241m.\u001b[39mmake(env_name), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./video\u001b[39m\u001b[38;5;124m'\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m video_env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\rl\\core.py:308\u001b[0m, in \u001b[0;36mAgent.test\u001b[1;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# Obtain the initial observation by resetting the environment.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m--> 308\u001b[0m observation \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mprocess_observation(observation)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitor.py:39\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_reset()\n\u001b[0;32m     38\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_after_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitor.py:185\u001b[0m, in \u001b[0;36mMonitor._after_reset\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Reset the stat count\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats_recorder\u001b[38;5;241m.\u001b[39mafter_reset(observation)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_video_recorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Bump *after* all reset activity has finished\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitor.py:206\u001b[0m, in \u001b[0;36mMonitor.reset_video_recorder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Start recording the next video.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# TODO: calculate a more correct 'episode_id' upon merge\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder \u001b[38;5;241m=\u001b[39m video_recorder\u001b[38;5;241m.\u001b[39mVideoRecorder(\n\u001b[0;32m    201\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv,\n\u001b[0;32m    202\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.video.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.video\u001b[39m\u001b[38;5;132;01m{:06}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_prefix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_infix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_id)),\n\u001b[0;32m    203\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_id},\n\u001b[0;32m    204\u001b[0m     enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_video_enabled(),\n\u001b[0;32m    205\u001b[0m )\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_recorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:116\u001b[0m, in \u001b[0;36mVideoRecorder.capture_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_ansi_frame(frame)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_image_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:162\u001b[0m, in \u001b[0;36mVideoRecorder._encode_image_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_encode_image_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mImageEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframes_per_sec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_frames_per_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mversion_info\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:255\u001b[0m, in \u001b[0;36mImageEncoder.__init__\u001b[1;34m(self, output_path, frame_shape, frames_per_sec, output_frames_per_sec)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFound neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll need to install avconv with `sudo apt-get install libav-tools`.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart()\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "mejor_epi = -1\n",
    "mejor_reward = -1\n",
    "\n",
    "# cargar mejor modelo\n",
    "dqn.load_weights('best_model_weights.h5f')\n",
    "\n",
    "# test normal + guardar recompensas\n",
    "history = dqn.test(env, nb_episodes=30, visualize=False)\n",
    "episode_rewards = history.history['episode_reward']\n",
    "np.save('test_rewards.npy', episode_rewards)\n",
    "\n",
    "# Mostrar los resultados\n",
    "mejor_reward = np.max(episode_rewards)\n",
    "mejor_epi = np.argmax(episode_rewards) + 1\n",
    "print(f\"\\nMejor Episodio {mejor_epi} con Recompensa = {mejor_reward}\")\n",
    "\n",
    "# Guardar la mejor recompensa en un archivo\n",
    "with open('mejor_ejecucion.txt', 'w') as f:\n",
    "    f.write(f\"Mejor episodio: {mejor_epi} con Recompensa: {mejor_reward}\\n\")\n",
    "    \n",
    "# correr episodio con video\n",
    "video_env = Monitor(gym.make(env_name), './video', force=True)\n",
    "dqn.test(video_env, nb_episodes=1, visualize=False)\n",
    "video_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rewards = np.load('test_rewards.npy')\n",
    "plt.plot(rewards)\n",
    "plt.title(\"Recompensa por episodio\")\n",
    "plt.xlabel(\"Episodio\")\n",
    "plt.ylabel(\"Recompensa\")\n",
    "plt.grid()\n",
    "plt.savefig(\"grafico_recompensas.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NAlu8b1Gb2b"
   },
   "source": [
    "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall tensorflow\n",
    "%pip install tensorflow-gpu==2.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANFQiicXK3sO"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_apr_g9",
   "language": "python",
   "name": "env_apr_g9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
