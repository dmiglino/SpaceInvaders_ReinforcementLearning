{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUehXgCyIRdq"
   },
   "source": [
    "# Actividad - Proyecto práctico\n",
    "\n",
    "\n",
    "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
    "*   Alumno 1: Granizo, Mateo\n",
    "*   Alumno 2: Maiolo, Pablo\n",
    "*   Alumno 3: Miglino, Diego\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwpYlnjWJhS9"
   },
   "source": [
    "---\n",
    "## **PARTE 1** - Instalación y requisitos previos\n",
    "\n",
    "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
    "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
    "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
    "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
    "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU2BPrK2JkP0"
   },
   "source": [
    "---\n",
    "### 1.1. Preparar enviroment (solo local)\n",
    "\n",
    "\n",
    "\n",
    "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
    "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
    "2. Instalar Anaconda\n",
    "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
    "\n",
    "\n",
    "```\n",
    "conda create --name miar_rl python=3.8\n",
    "conda activate miar_rl\n",
    "cd \"PATH_TO_FOLDER\"\n",
    "conda install git\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "\n",
    "4. Abrir la notebook con *jupyter-notebook*.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "jupyter-notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-kixNPiJqTc"
   },
   "source": [
    "---\n",
    "### 1.2. Localizar entorno de trabajo: Google colab o local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_YDFwZ-JscI",
    "outputId": "01a99aa0-3d4e-4cd1-b1bc-309aef65070a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
    "mount='/content/gdrive'\n",
    "drive_root = mount + \"/My Drive/08_MIAR/actividades/TP_Grupal\"\n",
    "mount='./'\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dp_a1iBJ0tf"
   },
   "source": [
    "---\n",
    "### 1.3. Montar carpeta de datos local (solo Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6n7MIefJ21i",
    "outputId": "9a6fc610-9fb0-4f63-8562-46754d7d75fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en el directorio: \n",
      "['.git', '.ipynb_checkpoints', 'anaconda_projects', 'apr_g9_dqn_SpaceInvaders-v0_log.json', 'apr_g9_dqn_SpaceInvaders-v0_weights.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_10000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_10000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_100000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_100000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1000000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1000000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1002500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1002500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1005000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1005000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1007500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1007500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1010000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1010000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1012500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1012500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1015000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1015000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1017500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1017500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1020000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1020000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1022500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1022500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_102500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_102500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1025000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1025000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1027500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1027500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1030000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1030000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1032500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1032500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1035000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1035000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1037500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1037500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1040000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1040000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1042500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1042500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1045000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1045000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1047500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1047500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_105000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_105000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1050000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1050000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1052500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1052500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1055000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1055000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1057500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1057500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1060000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1060000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1062500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1062500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1065000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1065000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1067500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1067500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1070000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1070000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1072500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1072500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_107500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_107500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1075000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1075000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1077500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1077500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1080000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1080000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1082500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1082500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1085000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1085000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1087500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1087500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1090000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1090000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1092500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1092500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1095000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1095000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1097500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1097500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_110000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_110000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1100000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1100000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1102500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1102500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1105000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1105000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1107500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1107500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1110000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1110000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1112500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1112500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1115000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1115000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1117500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1117500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1120000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1120000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1122500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1122500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_112500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_112500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1125000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1125000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1127500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1127500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1130000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1130000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1132500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1132500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1135000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1135000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1137500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1137500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1140000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1140000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1142500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1142500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1145000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1145000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1147500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1147500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_115000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_115000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1150000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1150000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1152500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1152500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1155000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1155000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1157500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1157500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1160000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1160000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1162500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1162500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1165000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1165000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1167500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1167500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1170000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1170000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1172500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1172500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_117500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_117500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1175000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1175000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1177500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1177500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1180000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1180000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1182500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1182500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1185000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1185000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1187500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1187500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1190000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1190000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1192500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1192500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1195000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1195000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1197500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1197500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_120000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_120000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1200000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1200000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1202500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1202500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1205000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1205000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1207500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1207500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1210000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1210000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1212500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1212500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1215000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1215000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1217500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1217500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1220000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1220000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1222500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1222500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_122500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_122500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1225000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1225000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1227500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1227500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1230000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1230000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1232500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1232500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1235000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1235000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1237500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1237500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1240000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1240000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1242500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1242500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1245000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1245000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1247500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1247500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_12500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_12500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_125000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_125000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1250000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1250000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1252500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1252500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1255000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1255000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1257500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1257500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1260000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1260000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1262500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1262500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1265000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1265000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1267500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1267500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1270000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1270000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1272500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1272500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_127500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_127500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1275000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1275000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1277500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1277500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1280000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1280000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1282500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1282500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1285000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1285000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1287500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1287500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1290000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1290000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1292500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1292500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1295000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1295000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1297500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1297500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_130000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_130000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1300000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1300000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1302500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1302500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1305000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1305000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1307500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1307500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1310000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1310000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1312500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1312500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1315000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1315000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1317500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1317500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1320000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1320000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1322500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1322500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_132500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_132500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1325000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1325000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1327500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1327500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1330000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1330000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1332500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1332500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1335000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1335000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1337500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1337500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1340000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1340000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1342500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1342500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1345000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1345000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1347500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1347500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_135000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_135000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1350000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1350000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1352500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1352500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1355000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1355000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1357500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1357500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1360000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1360000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1362500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1362500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1365000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1365000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1367500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1367500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1370000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1370000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1372500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1372500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_137500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_137500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1375000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1375000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1377500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1377500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1380000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1380000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1382500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1382500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1385000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1385000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1387500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1387500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1390000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1390000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1392500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1392500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1395000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1395000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1397500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1397500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_140000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_140000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1400000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1400000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1402500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1402500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1405000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1405000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1407500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1407500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1410000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1410000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1412500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1412500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1415000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1415000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1417500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1417500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1420000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1420000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1422500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1422500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_142500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_142500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1425000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1425000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1427500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1427500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1430000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1430000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1432500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1432500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1435000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1435000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1437500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1437500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1440000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1440000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1442500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1442500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1445000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1445000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1447500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1447500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_145000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_145000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1450000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1450000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1452500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1452500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1455000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1455000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1457500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1457500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1460000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1460000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1462500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1462500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1465000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1465000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1467500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1467500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1470000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1470000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1472500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1472500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_147500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_147500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1475000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1475000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1477500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1477500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1480000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1480000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1482500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1482500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1485000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1485000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1487500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1487500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1490000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1490000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1492500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1492500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1495000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1495000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1497500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1497500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_15000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_15000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_150000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_150000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1500000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1500000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1502500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1502500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1505000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1505000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1507500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1507500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1510000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1510000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1512500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1512500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1515000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1515000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1517500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1517500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1520000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1520000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1522500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1522500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_152500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_152500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1525000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1525000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1527500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1527500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1530000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1530000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1532500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1532500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1535000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1535000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1537500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1537500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1540000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1540000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1542500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1542500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1545000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1545000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1547500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1547500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_155000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_155000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1550000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1550000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1552500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1552500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1555000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1555000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1557500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1557500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1560000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1560000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1562500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1562500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1565000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1565000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1567500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1567500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1570000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1570000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1572500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1572500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_157500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_157500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1575000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1575000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1577500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1577500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1580000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1580000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1582500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1582500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1585000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1585000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1587500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1587500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1590000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1590000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1592500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1592500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1595000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1595000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1597500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1597500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_160000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_160000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1600000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1600000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1602500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1602500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1605000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1605000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1607500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1607500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1610000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1610000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1612500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1612500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1615000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1615000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1617500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1617500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1620000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1620000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1622500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1622500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_162500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_162500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1625000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1625000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1627500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1627500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1630000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1630000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1632500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1632500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1635000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1635000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1637500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1637500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1640000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1640000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1642500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1642500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1645000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1645000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1647500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1647500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_165000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_165000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1650000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1650000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1652500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1652500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1655000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1655000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1657500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1657500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1660000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1660000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1662500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1662500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1665000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1665000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1667500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1667500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1670000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1670000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1672500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1672500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_167500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_167500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1675000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1675000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1677500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1677500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1680000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1680000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1682500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1682500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1685000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1685000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1687500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1687500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1690000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1690000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1692500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1692500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1695000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1695000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1697500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1697500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_170000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_170000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1700000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1700000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1702500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1702500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1705000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1705000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1707500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1707500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1710000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1710000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1712500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1712500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1715000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1715000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1717500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1717500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1720000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1720000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1722500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1722500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_172500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_172500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1725000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1725000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1727500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1727500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1730000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1730000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1732500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1732500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1735000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1735000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1737500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1737500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1740000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1740000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1742500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1742500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1745000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1745000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1747500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1747500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_17500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_17500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_175000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_175000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1750000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1750000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1752500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1752500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1755000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1755000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1757500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1757500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1760000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1760000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1762500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1762500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1765000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1765000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1767500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1767500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1770000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1770000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1772500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1772500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_177500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_177500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1775000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1775000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1777500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1777500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1780000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1780000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1782500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1782500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1785000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1785000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1787500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1787500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1790000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1790000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1792500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1792500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1795000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1795000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1797500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1797500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_180000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_180000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1800000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1800000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1802500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1802500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1805000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1805000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1807500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1807500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1810000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1810000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1812500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1812500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1815000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1815000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1817500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1817500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1820000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1820000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1822500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1822500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_182500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_182500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1825000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1825000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1827500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1827500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1830000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1830000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1832500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1832500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1835000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1835000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1837500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1837500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1840000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1840000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1842500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1842500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1845000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1845000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1847500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1847500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_185000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_185000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1850000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1850000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1852500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1852500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1855000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1855000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1857500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1857500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1860000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1860000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1862500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1862500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1865000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1865000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1867500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1867500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1870000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1870000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1872500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1872500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_187500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_187500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1875000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1875000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1877500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1877500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1880000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1880000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1882500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1882500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1885000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1885000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1887500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1887500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1890000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1890000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1892500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1892500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1895000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1895000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1897500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1897500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_190000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_190000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1900000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1900000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1902500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1902500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1905000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1905000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1907500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1907500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1910000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1910000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1912500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1912500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1915000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1915000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1917500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1917500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1920000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1920000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1922500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1922500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_192500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_192500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1925000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1925000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1927500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1927500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1930000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1930000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1932500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1932500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1935000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1935000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1937500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1937500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1940000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1940000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1942500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1942500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1945000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1945000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1947500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1947500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_195000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_195000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1950000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1950000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1952500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1952500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1955000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1955000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1957500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1957500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1960000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1960000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1962500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1962500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1965000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1965000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1967500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1967500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1970000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1970000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1972500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1972500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_197500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_197500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1975000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1975000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1977500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1977500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1980000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1980000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1982500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1982500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1985000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1985000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1987500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1987500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_1990000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_1990000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_20000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_20000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_200000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_200000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_202500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_202500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_205000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_205000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_207500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_207500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_210000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_210000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_212500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_212500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_215000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_215000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_217500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_217500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_220000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_220000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_222500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_222500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_22500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_22500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_225000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_225000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_227500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_227500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_230000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_230000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_232500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_232500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_235000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_235000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_237500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_237500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_240000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_240000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_242500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_242500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_245000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_245000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_247500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_247500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_2500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_2500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_25000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_25000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_250000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_250000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_252500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_252500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_255000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_255000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_257500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_257500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_260000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_260000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_262500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_262500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_265000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_265000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_267500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_267500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_270000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_270000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_272500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_272500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_27500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_27500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_275000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_275000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_277500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_277500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_280000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_280000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_282500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_282500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_285000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_285000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_287500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_287500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_290000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_290000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_292500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_292500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_295000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_295000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_297500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_297500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_30000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_30000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_300000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_300000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_302500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_302500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_305000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_305000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_307500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_307500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_310000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_310000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_312500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_312500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_315000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_315000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_317500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_317500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_320000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_320000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_322500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_322500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_32500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_32500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_325000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_325000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_327500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_327500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_330000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_330000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_332500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_332500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_335000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_335000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_337500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_337500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_340000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_340000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_342500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_342500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_345000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_345000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_347500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_347500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_35000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_35000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_350000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_350000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_352500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_352500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_355000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_355000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_357500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_357500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_360000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_360000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_362500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_362500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_365000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_365000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_367500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_367500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_370000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_370000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_372500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_372500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_37500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_37500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_375000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_375000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_377500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_377500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_380000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_380000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_382500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_382500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_385000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_385000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_387500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_387500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_390000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_390000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_392500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_392500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_395000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_395000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_397500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_397500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_40000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_40000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_400000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_400000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_402500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_402500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_405000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_405000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_407500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_407500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_410000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_410000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_412500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_412500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_415000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_415000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_417500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_417500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_420000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_420000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_422500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_422500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_42500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_42500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_425000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_425000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_427500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_427500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_430000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_430000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_432500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_432500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_435000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_435000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_437500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_437500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_440000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_440000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_442500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_442500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_445000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_445000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_447500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_447500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_45000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_45000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_450000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_450000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_452500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_452500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_455000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_455000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_457500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_457500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_460000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_460000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_462500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_462500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_465000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_465000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_467500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_467500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_470000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_470000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_472500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_472500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_47500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_47500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_475000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_475000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_477500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_477500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_480000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_480000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_482500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_482500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_485000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_485000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_487500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_487500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_490000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_490000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_492500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_492500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_495000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_495000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_497500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_497500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_5000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_5000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_50000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_50000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_500000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_500000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_502500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_502500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_505000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_505000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_507500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_507500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_510000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_510000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_512500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_512500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_515000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_515000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_517500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_517500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_520000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_520000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_522500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_522500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_52500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_52500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_525000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_525000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_527500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_527500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_530000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_530000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_532500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_532500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_535000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_535000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_537500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_537500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_540000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_540000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_542500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_542500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_545000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_545000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_547500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_547500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_55000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_55000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_550000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_550000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_552500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_552500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_555000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_555000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_557500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_557500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_560000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_560000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_562500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_562500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_565000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_565000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_567500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_567500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_570000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_570000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_572500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_572500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_57500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_57500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_575000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_575000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_577500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_577500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_580000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_580000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_582500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_582500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_585000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_585000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_587500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_587500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_590000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_590000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_592500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_592500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_595000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_595000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_597500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_597500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_60000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_60000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_600000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_600000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_602500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_602500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_605000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_605000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_607500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_607500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_610000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_610000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_612500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_612500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_615000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_615000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_617500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_617500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_620000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_620000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_622500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_622500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_62500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_62500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_625000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_625000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_627500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_627500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_630000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_630000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_632500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_632500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_635000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_635000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_637500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_637500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_640000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_640000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_642500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_642500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_645000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_645000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_647500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_647500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_65000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_65000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_650000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_650000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_652500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_652500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_655000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_655000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_657500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_657500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_660000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_660000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_662500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_662500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_665000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_665000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_667500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_667500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_670000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_670000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_672500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_672500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_67500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_67500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_675000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_675000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_677500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_677500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_680000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_680000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_682500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_682500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_685000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_685000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_687500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_687500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_690000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_690000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_692500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_692500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_695000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_695000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_697500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_697500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_70000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_70000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_700000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_700000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_702500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_702500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_705000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_705000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_707500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_707500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_710000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_710000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_712500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_712500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_715000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_715000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_717500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_717500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_720000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_720000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_722500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_722500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_72500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_72500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_725000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_725000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_727500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_727500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_730000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_730000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_732500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_732500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_735000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_735000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_737500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_737500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_740000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_740000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_742500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_742500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_745000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_745000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_747500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_747500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_7500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_7500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_75000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_75000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_750000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_750000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_752500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_752500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_755000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_755000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_757500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_757500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_760000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_760000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_762500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_762500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_765000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_765000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_767500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_767500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_770000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_770000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_772500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_772500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_77500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_77500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_775000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_775000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_777500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_777500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_780000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_780000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_782500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_782500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_785000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_785000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_787500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_787500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_790000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_790000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_792500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_792500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_795000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_795000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_797500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_797500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_80000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_80000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_800000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_800000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_802500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_802500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_805000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_805000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_807500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_807500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_810000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_810000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_812500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_812500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_815000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_815000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_817500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_817500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_820000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_820000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_822500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_822500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_82500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_82500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_825000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_825000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_827500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_827500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_830000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_830000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_832500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_832500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_835000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_835000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_837500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_837500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_840000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_840000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_842500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_842500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_845000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_845000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_847500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_847500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_85000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_85000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_850000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_850000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_852500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_852500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_855000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_855000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_857500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_857500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_860000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_860000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_862500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_862500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_865000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_865000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_867500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_867500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_870000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_870000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_872500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_872500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_87500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_87500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_875000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_875000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_877500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_877500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_880000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_880000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_882500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_882500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_885000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_885000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_887500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_887500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_890000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_890000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_892500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_892500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_895000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_895000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_897500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_897500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_90000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_90000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_900000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_900000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_902500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_902500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_905000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_905000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_907500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_907500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_910000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_910000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_912500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_912500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_915000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_915000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_917500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_917500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_920000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_920000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_922500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_922500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_92500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_92500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_925000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_925000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_927500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_927500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_930000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_930000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_932500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_932500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_935000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_935000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_937500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_937500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_940000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_940000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_942500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_942500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_945000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_945000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_947500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_947500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_95000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_95000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_950000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_950000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_952500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_952500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_955000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_955000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_957500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_957500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_960000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_960000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_962500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_962500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_965000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_965000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_967500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_967500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_970000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_970000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_972500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_972500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_97500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_97500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_975000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_975000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_977500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_977500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_980000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_980000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_982500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_982500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_985000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_985000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_987500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_987500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_990000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_990000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_992500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_992500.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_995000.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_995000.h5f.index', 'apr_g9_dqn_SpaceInvaders-v0_weights_997500.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights_997500.h5f.index', 'APR_Grupo_9.ipynb', 'best_model_weights.h5f.data-00000-of-00001', 'best_model_weights.h5f.index', 'checkpoint', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    # Mount the Google Drive at mount\n",
    "    print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "    drive.mount(mount)\n",
    "\n",
    "    # Create drive_root if it doesn't exist\n",
    "    create_drive_root = True\n",
    "    if create_drive_root:\n",
    "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "      os.makedirs(drive_root, exist_ok=True)\n",
    "\n",
    "    # Change to the directory\n",
    "    print(\"\\nColab: Changing directory to \", drive_root)\n",
    "    %cd $drive_root\n",
    "# Verify we're in the correct working directory\n",
    "%pwd\n",
    "print(\"Archivos en el directorio: \")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1ZSL5bpJ560"
   },
   "source": [
    "---\n",
    "### 1.4. Instalar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UbVRjvHCJ8UF",
    "outputId": "fe539761-ae1b-4e9f-95de-9a3cfa9ae8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (0.17.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
      "Collecting git+https://github.com/Kojoley/atari-py.git\n",
      "  Cloning https://github.com/Kojoley/atari-py.git to c:\\users\\dmigl\\appdata\\local\\temp\\pip-req-build-7x8nbzoz\n",
      "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from atari-py==1.2.2) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git 'C:\\Users\\dmigl\\AppData\\Local\\Temp\\pip-req-build-7x8nbzoz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet==1.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet==1.5.0) (1.0.0)\n",
      "Requirement already satisfied: h5py==3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from h5py==3.1.0) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras-rl2==1.0.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from keras-rl2==1.0.5) (2.5.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Keras==2.2.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.10.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (6.0.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (3.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from Keras==2.2.4) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow==2.5.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow==2.5.3) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.3) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.7.4.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: agents==1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (2.5.3)\n",
      "Requirement already satisfied: gym in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (0.17.3)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from agents==1.4.0) (0.18.14)\n",
      "Requirement already satisfied: scipy in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from gym->agents==1.4.0) (1.6.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from ruamel.yaml->agents==1.4.0) (0.2.8)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.34.1)\n",
      "Requirement already satisfied: future in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym->agents==1.4.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (75.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ejecutar solo la primera vez..\n",
    "\n",
    "if IN_COLAB:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install tensorflow==2.12\n",
    "else:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install pyglet==1.5.0\n",
    "  %pip install h5py==3.1.0\n",
    "  %pip install Pillow==9.5.0\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install Keras==2.2.4\n",
    "  %pip install tensorflow==2.5.3\n",
    "  %pip install torch==2.0.1\n",
    "  %pip install agents==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hzP_5ZuGb2X"
   },
   "source": [
    "---\n",
    "## **PARTE 2**. Enunciado\n",
    "\n",
    "Consideraciones a tener en cuenta:\n",
    "\n",
    "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
    "\n",
    "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
    "\n",
    "Este proyecto práctico consta de tres partes:\n",
    "\n",
    "1.   Implementar la red neuronal que se usará en la solución\n",
    "2.   Implementar las distintas piezas de la solución DQN\n",
    "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
    "\n",
    "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
    "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
    "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
    "* Cada alumno deberá de subir la solución de forma individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_b3mzw8IzJP"
   },
   "source": [
    "---\n",
    "## **PARTE 3**. Desarrollo y preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duPmUNOVGb2a"
   },
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j3eRhgI-Gb2a"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4jgQjzoGb2a"
   },
   "source": [
    "#### Configuración base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwOE6I_KGb2a",
    "outputId": "941f9c3a-e542-42e6-bd55-a097f9b71828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de acciones disponibles: 6\n",
      "Formato de las observaciones: Box(0, 255, (210, 160, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "env_name = 'SpaceInvaders-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "print(\"Numero de acciones disponibles: \" + str(nb_actions))\n",
    "print(\"Formato de las observaciones: \" + str(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9jGEZUcpGb2a"
   },
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class SaveBestRewardCallback(Callback):\n",
    "    def __init__(self, env, filename='best_model.h5f', test_episodes=5, test_interval=5000):\n",
    "        self.env = env\n",
    "        self.filename = filename\n",
    "        self.test_episodes = test_episodes\n",
    "        self.test_interval = test_interval\n",
    "        self.best_reward = -np.inf\n",
    "        self.steps_since_last_eval = 0\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.steps_since_last_eval += 1\n",
    "\n",
    "        if self.steps_since_last_eval >= self.test_interval:\n",
    "            self.steps_since_last_eval = 0\n",
    "            # Test the agent\n",
    "            history = self.model.test(self.env, nb_episodes=self.test_episodes, visualize=False, verbose=0)\n",
    "            rewards = history.history['episode_reward']\n",
    "            avg_reward = np.mean(rewards)\n",
    "\n",
    "            print(f\"\\nEvaluated after {step} steps — Avg reward: {avg_reward:.2f}\")\n",
    "\n",
    "            if avg_reward > self.best_reward:\n",
    "                print(f\"New best average reward: {avg_reward:.2f}, saving weights to {self.filename}\")\n",
    "                self.best_reward = avg_reward\n",
    "                self.model.save_weights(self.filename, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yitXTADGb2b"
   },
   "source": [
    "1. Implementación de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "O4GKrfWSGb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 100800)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                1612816   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 102       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,613,462\n",
      "Trainable params: 1,613,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# modelo simple - no usar\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(nb_actions))\n",
    "# model.add(Activation('linear'))\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "(4, 84, 84)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# modelo mas complejo - usar este\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "print(K.image_data_format())\n",
    "print(input_shape)\n",
    "if K.image_data_format() == 'channels_last':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_data_format() == 'channels_first':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB9-_5HPGb2b"
   },
   "source": [
    "2. Implementación de la solución DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "foSlxWH1Gb2b"
   },
   "outputs": [],
   "source": [
    "# memoria para almacenar la experiencia del agente\n",
    "memory = SequentialMemory(limit=500, window_length=WINDOW_LENGTH)\n",
    "\n",
    "# processor\n",
    "processor = AtariProcessor()\n",
    "\n",
    "# policy que el agente va a seguir\n",
    "#policy = BoltzmannQPolicy()\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
    "                              value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=100)\n",
    "\n",
    "# definicion del agente\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
    "               memory=memory, processor=processor,\n",
    "               nb_steps_warmup=500, gamma=.99,\n",
    "               target_model_update=100,\n",
    "               train_interval=4)\n",
    "\n",
    "# compilacion del agente\n",
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 2 (500 steps performed)\n",
      "500/500 [==============================] - 14s 29ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.006 - mae: 0.104 - mean_q: 0.177 - mean_eps: 0.100 - ale.lives: 2.270\n",
      "\n",
      "Interval 3 (1000 steps performed)\n",
      "500/500 [==============================] - 14s 28ms/step - reward: 0.0140\n",
      "Interval 4 (1500 steps performed)\n",
      "500/500 [==============================] - 13s 26ms/step - reward: 0.0160\n",
      "Interval 5 (2000 steps performed)\n",
      "500/500 [==============================] - 13s 26ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.009 - mae: 0.526 - mean_q: 0.695 - mean_eps: 0.100 - ale.lives: 2.736\n",
      "\n",
      "Interval 6 (2500 steps performed)\n",
      "500/500 [==============================] - 15s 30ms/step - reward: 0.0200\n",
      "Interval 7 (3000 steps performed)\n",
      "500/500 [==============================] - 14s 28ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.010 - mae: 0.929 - mean_q: 1.182 - mean_eps: 0.100 - ale.lives: 2.858\n",
      "\n",
      "Interval 8 (3500 steps performed)\n",
      "500/500 [==============================] - 15s 29ms/step - reward: 0.0180\n",
      "Interval 9 (4000 steps performed)\n",
      "500/500 [==============================] - 15s 29ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.007 - mae: 1.253 - mean_q: 1.562 - mean_eps: 0.100 - ale.lives: 2.204\n",
      "\n",
      "Interval 10 (4500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0101\n",
      "Evaluated after 247 steps — Avg reward: 5.00\n",
      "New best average reward: 5.00, saving weights to best_model_weights.h5f\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.012 - mae: 1.542 - mean_q: 1.903 - mean_eps: 0.100 - ale.lives: 2.246\n",
      "\n",
      "Interval 11 (5000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 12 (5500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 13 (6000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.842\n",
      "\n",
      "Interval 14 (6500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.552\n",
      "\n",
      "Interval 15 (7000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 16 (7500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 17 (8000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 18 (8500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 19 (9000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 20 (9500 steps performed)\n",
      "490/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 16s 31ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 21 (10000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 22 (10500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 23 (11000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.870\n",
      "\n",
      "Interval 24 (11500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.528\n",
      "\n",
      "Interval 25 (12000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "Interval 26 (12500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 27 (13000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.990\n",
      "\n",
      "Interval 28 (13500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.586\n",
      "\n",
      "Interval 29 (14000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 30 (14500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 465 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 15s 30ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 31 (15000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 32 (15500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 33 (16000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.778\n",
      "\n",
      "Interval 34 (16500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.510\n",
      "\n",
      "Interval 35 (17000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 36 (17500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 37 (18000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.970\n",
      "\n",
      "Interval 38 (18500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.558\n",
      "\n",
      "Interval 39 (19000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 40 (19500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 449 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 14s 27ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.160\n",
      "\n",
      "Interval 41 (20000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 42 (20500 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 43 (21000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.862\n",
      "\n",
      "Interval 44 (21500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 45 (22000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "Interval 46 (22500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 47 (23000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.000\n",
      "\n",
      "Interval 48 (23500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.658\n",
      "\n",
      "Interval 49 (24000 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0100\n",
      "Interval 50 (24500 steps performed)\n",
      "491/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 498 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 13s 26ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 51 (25000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.154\n",
      "\n",
      "Interval 52 (25500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 53 (26000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.794\n",
      "\n",
      "Interval 54 (26500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.530\n",
      "\n",
      "Interval 55 (27000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 56 (27500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 57 (28000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.976\n",
      "\n",
      "Interval 58 (28500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.606\n",
      "\n",
      "Interval 59 (29000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 60 (29500 steps performed)\n",
      "489/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 484 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 15s 29ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 61 (30000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 62 (30500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.084\n",
      "\n",
      "Interval 63 (31000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.834\n",
      "\n",
      "Interval 64 (31500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.540\n",
      "\n",
      "Interval 65 (32000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 66 (32500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 67 (33000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.030\n",
      "\n",
      "Interval 68 (33500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.664\n",
      "\n",
      "Interval 69 (34000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.572\n",
      "\n",
      "Interval 70 (34500 steps performed)\n",
      "489/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 501 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 14s 29ms/step - reward: 0.0060\n",
      "Interval 71 (35000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.146\n",
      "\n",
      "Interval 72 (35500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 73 (36000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.818\n",
      "\n",
      "Interval 74 (36500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.544\n",
      "\n",
      "Interval 75 (37000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "Interval 76 (37500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.096\n",
      "\n",
      "Interval 77 (38000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.068\n",
      "\n",
      "Interval 78 (38500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.664\n",
      "\n",
      "Interval 79 (39000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 80 (39500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 511 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 13s 26ms/step - reward: 0.0060\n",
      "Interval 81 (40000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 82 (40500 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 83 (41000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.858\n",
      "\n",
      "Interval 84 (41500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.512\n",
      "\n",
      "Interval 85 (42000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "Interval 86 (42500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 87 (43000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.018\n",
      "\n",
      "Interval 88 (43500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.654\n",
      "\n",
      "Interval 89 (44000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 90 (44500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 492 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 14s 28ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 91 (45000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 92 (45500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 93 (46000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.870\n",
      "\n",
      "Interval 94 (46500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.540\n",
      "\n",
      "Interval 95 (47000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 96 (47500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 97 (48000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.022\n",
      "\n",
      "Interval 98 (48500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.612\n",
      "\n",
      "Interval 99 (49000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 100 (49500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 472 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 14s 29ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 101 (50000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 102 (50500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 103 (51000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.794\n",
      "\n",
      "Interval 104 (51500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.588\n",
      "\n",
      "Interval 105 (52000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "Interval 106 (52500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 107 (53000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.018\n",
      "\n",
      "Interval 108 (53500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.590\n",
      "\n",
      "Interval 109 (54000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 110 (54500 steps performed)\n",
      "492/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 472 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 18s 35ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 111 (55000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.080\n",
      "\n",
      "Interval 112 (55500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 113 (56000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.834\n",
      "\n",
      "Interval 114 (56500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.524\n",
      "\n",
      "Interval 115 (57000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "Interval 116 (57500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.096\n",
      "\n",
      "Interval 117 (58000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.992\n",
      "\n",
      "Interval 118 (58500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.616\n",
      "\n",
      "Interval 119 (59000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 120 (59500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 485 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 18s 35ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 121 (60000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 122 (60500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 123 (61000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 124 (61500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.574\n",
      "\n",
      "Interval 125 (62000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "Interval 126 (62500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 127 (63000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.018\n",
      "\n",
      "Interval 128 (63500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.628\n",
      "\n",
      "Interval 129 (64000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 130 (64500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 17s 33ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 131 (65000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 132 (65500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 133 (66000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.810\n",
      "\n",
      "Interval 134 (66500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 135 (67000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "Interval 136 (67500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 137 (68000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 138 (68500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.638\n",
      "\n",
      "Interval 139 (69000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "Interval 140 (69500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 487 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 18s 36ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.160\n",
      "\n",
      "Interval 141 (70000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 142 (70500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 143 (71000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.818\n",
      "\n",
      "Interval 144 (71500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.538\n",
      "\n",
      "Interval 145 (72000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "Interval 146 (72500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 147 (73000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.006\n",
      "\n",
      "Interval 148 (73500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.624\n",
      "\n",
      "Interval 149 (74000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "Interval 150 (74500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 481 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 17s 35ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 151 (75000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 152 (75500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 153 (76000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.850\n",
      "\n",
      "Interval 154 (76500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.504\n",
      "\n",
      "Interval 155 (77000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "Interval 156 (77500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 157 (78000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.922\n",
      "\n",
      "Interval 158 (78500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.586\n",
      "\n",
      "Interval 159 (79000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "Interval 160 (79500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0080\n",
      "Evaluated after 451 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 18s 37ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 161 (80000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 162 (80500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 163 (81000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.718\n",
      "\n",
      "Interval 164 (81500 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.572\n",
      "\n",
      "Interval 165 (82000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "Interval 166 (82500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 167 (83000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.980\n",
      "\n",
      "Interval 168 (83500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.592\n",
      "\n",
      "Interval 169 (84000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "Interval 170 (84500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 470 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 65ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 171 (85000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 172 (85500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 173 (86000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.814\n",
      "\n",
      "Interval 174 (86500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.510\n",
      "\n",
      "Interval 175 (87000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 176 (87500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 177 (88000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.928\n",
      "\n",
      "Interval 178 (88500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.570\n",
      "\n",
      "Interval 179 (89000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "Interval 180 (89500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 460 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 34s 67ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 181 (90000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 182 (90500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.098\n",
      "\n",
      "Interval 183 (91000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.938\n",
      "\n",
      "Interval 184 (91500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.576\n",
      "\n",
      "Interval 185 (92000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "Interval 186 (92500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 187 (93000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 188 (93500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.704\n",
      "\n",
      "Interval 189 (94000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.506\n",
      "\n",
      "Interval 190 (94500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 523 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 34s 67ms/step - reward: 0.0060\n",
      "Interval 191 (95000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 192 (95500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 193 (96000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.798\n",
      "\n",
      "Interval 194 (96500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.516\n",
      "\n",
      "Interval 195 (97000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 196 (97500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 197 (98000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 198 (98500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.566\n",
      "\n",
      "Interval 199 (99000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 200 (99500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 453 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 34s 68ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 201 (100000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 202 (100500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 203 (101000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.886\n",
      "\n",
      "Interval 204 (101500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.522\n",
      "\n",
      "Interval 205 (102000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "Interval 206 (102500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 207 (103000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.050\n",
      "\n",
      "Interval 208 (103500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.576\n",
      "\n",
      "Interval 209 (104000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "Interval 210 (104500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 477 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 34s 68ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 211 (105000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 212 (105500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 213 (106000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.806\n",
      "\n",
      "Interval 214 (106500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 215 (107000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "Interval 216 (107500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 217 (108000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.982\n",
      "\n",
      "Interval 218 (108500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.590\n",
      "\n",
      "Interval 219 (109000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "Interval 220 (109500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 465 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 35s 69ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 221 (110000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.172\n",
      "\n",
      "Interval 222 (110500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 223 (111000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.774\n",
      "\n",
      "Interval 224 (111500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 225 (112000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 226 (112500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.090\n",
      "\n",
      "Interval 227 (113000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.022\n",
      "\n",
      "Interval 228 (113500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.610\n",
      "\n",
      "Interval 229 (114000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 230 (114500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 472 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 231 (115000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 232 (115500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 233 (116000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.834\n",
      "\n",
      "Interval 234 (116500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.514\n",
      "\n",
      "Interval 235 (117000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 236 (117500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 237 (118000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 238 (118500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.598\n",
      "\n",
      "Interval 239 (119000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 240 (119500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 465 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 241 (120000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 242 (120500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 243 (121000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.822\n",
      "\n",
      "Interval 244 (121500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.520\n",
      "\n",
      "Interval 245 (122000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 246 (122500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 247 (123000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.008\n",
      "\n",
      "Interval 248 (123500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 249 (124000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 250 (124500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 484 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 251 (125000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 252 (125500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 253 (126000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.870\n",
      "\n",
      "Interval 254 (126500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 255 (127000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0080\n",
      "Interval 256 (127500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 257 (128000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.030\n",
      "\n",
      "Interval 258 (128500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.634\n",
      "\n",
      "Interval 259 (129000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 260 (129500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 261 (130000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.092\n",
      "\n",
      "Interval 262 (130500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 263 (131000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.886\n",
      "\n",
      "Interval 264 (131500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 265 (132000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 266 (132500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 267 (133000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.038\n",
      "\n",
      "Interval 268 (133500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.686\n",
      "\n",
      "Interval 269 (134000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.562\n",
      "\n",
      "Interval 270 (134500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 509 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "Interval 271 (135000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 272 (135500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 273 (136000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.882\n",
      "\n",
      "Interval 274 (136500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.522\n",
      "\n",
      "Interval 275 (137000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 276 (137500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 277 (138000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.024\n",
      "\n",
      "Interval 278 (138500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.674\n",
      "\n",
      "Interval 279 (139000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 280 (139500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 492 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.096\n",
      "\n",
      "Interval 281 (140000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 282 (140500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 283 (141000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.862\n",
      "\n",
      "Interval 284 (141500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.574\n",
      "\n",
      "Interval 285 (142000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 286 (142500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 287 (143000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.020\n",
      "\n",
      "Interval 288 (143500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.594\n",
      "\n",
      "Interval 289 (144000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 290 (144500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 477 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 291 (145000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 292 (145500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 293 (146000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.854\n",
      "\n",
      "Interval 294 (146500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.500\n",
      "\n",
      "Interval 295 (147000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 296 (147500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 297 (148000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.980\n",
      "\n",
      "Interval 298 (148500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.588\n",
      "\n",
      "Interval 299 (149000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 300 (149500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 464 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 301 (150000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.158\n",
      "\n",
      "Interval 302 (150500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 303 (151000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.842\n",
      "\n",
      "Interval 304 (151500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.544\n",
      "\n",
      "Interval 305 (152000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 306 (152500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 307 (153000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.006\n",
      "\n",
      "Interval 308 (153500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.638\n",
      "\n",
      "Interval 309 (154000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 310 (154500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 64ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 311 (155000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 312 (155500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.090\n",
      "\n",
      "Interval 313 (156000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.854\n",
      "\n",
      "Interval 314 (156500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.530\n",
      "\n",
      "Interval 315 (157000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 316 (157500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 317 (158000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.014\n",
      "\n",
      "Interval 318 (158500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.582\n",
      "\n",
      "Interval 319 (159000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 320 (159500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 467 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 64ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 321 (160000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 322 (160500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 323 (161000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.758\n",
      "\n",
      "Interval 324 (161500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.566\n",
      "\n",
      "Interval 325 (162000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 326 (162500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 327 (163000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.972\n",
      "\n",
      "Interval 328 (163500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.574\n",
      "\n",
      "Interval 329 (164000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 330 (164500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 453 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 331 (165000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.146\n",
      "\n",
      "Interval 332 (165500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 333 (166000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.794\n",
      "\n",
      "Interval 334 (166500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 335 (167000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 336 (167500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 337 (168000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.996\n",
      "\n",
      "Interval 338 (168500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.606\n",
      "\n",
      "Interval 339 (169000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 340 (169500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 473 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 341 (170000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 342 (170500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.084\n",
      "\n",
      "Interval 343 (171000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.886\n",
      "\n",
      "Interval 344 (171500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.500\n",
      "\n",
      "Interval 345 (172000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "Interval 346 (172500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 347 (173000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.038\n",
      "\n",
      "Interval 348 (173500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.680\n",
      "\n",
      "Interval 349 (174000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 350 (174500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 501 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 67ms/step - reward: 0.0060\n",
      "Interval 351 (175000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 352 (175500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 353 (176000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.770\n",
      "\n",
      "Interval 354 (176500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.524\n",
      "\n",
      "Interval 355 (177000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 356 (177500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 357 (178000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.950\n",
      "\n",
      "Interval 358 (178500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.570\n",
      "\n",
      "Interval 359 (179000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 360 (179500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 458 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 361 (180000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 362 (180500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 363 (181000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.830\n",
      "\n",
      "Interval 364 (181500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.546\n",
      "\n",
      "Interval 365 (182000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 366 (182500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 367 (183000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.014\n",
      "\n",
      "Interval 368 (183500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.696\n",
      "\n",
      "Interval 369 (184000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 370 (184500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 502 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0060\n",
      "Interval 371 (185000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 372 (185500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 373 (186000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.902\n",
      "\n",
      "Interval 374 (186500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.524\n",
      "\n",
      "Interval 375 (187000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 376 (187500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 377 (188000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.026\n",
      "\n",
      "Interval 378 (188500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.606\n",
      "\n",
      "Interval 379 (189000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 380 (189500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 480 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 381 (190000 steps performed)\n",
      "339/500 [===================>..........] - ETA: 1s - reward: 0.0088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000017BF8622700>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 382, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 378, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\dmigl\\anaconda3\\envs\\env_apr_g9\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x0000017BF5DB9DB0; to 'Win32Window' at 0x0000017BF53B44F0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 382 (190500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 383 (191000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.798\n",
      "\n",
      "Interval 384 (191500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.538\n",
      "\n",
      "Interval 385 (192000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "Interval 386 (192500 steps performed)\n",
      "500/500 [==============================] - 5s 11ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 387 (193000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.008\n",
      "\n",
      "Interval 388 (193500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.624\n",
      "\n",
      "Interval 389 (194000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "Interval 390 (194500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 477 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 529s 1s/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 391 (195000 steps performed)\n",
      "500/500 [==============================] - 2s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 402 (200500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 403 (201000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.818\n",
      "\n",
      "Interval 404 (201500 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.502\n",
      "\n",
      "Interval 405 (202000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0060\n",
      "Interval 406 (202500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 407 (203000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.998\n",
      "\n",
      "Interval 408 (203500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.546\n",
      "\n",
      "Interval 409 (204000 steps performed)\n",
      "500/500 [==============================] - 3s 7ms/step - reward: 0.0100\n",
      "Interval 410 (204500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 452 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 411 (205000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 412 (205500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 413 (206000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 414 (206500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.538\n",
      "\n",
      "Interval 415 (207000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0060\n",
      "Interval 416 (207500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 417 (208000 steps performed)\n",
      "500/500 [==============================] - 3s 5ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.998\n",
      "\n",
      "Interval 418 (208500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.642\n",
      "\n",
      "Interval 419 (209000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.572\n",
      "\n",
      "Interval 420 (209500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 502 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "Interval 421 (210000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 422 (210500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 423 (211000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.892\n",
      "\n",
      "Interval 424 (211500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.532\n",
      "\n",
      "Interval 425 (212000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 426 (212500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 427 (213000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 428 (213500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.588\n",
      "\n",
      "Interval 429 (214000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 430 (214500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 466 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 66ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 431 (215000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 432 (215500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 433 (216000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.846\n",
      "\n",
      "Interval 434 (216500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.552\n",
      "\n",
      "Interval 435 (217000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 436 (217500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 437 (218000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.986\n",
      "\n",
      "Interval 438 (218500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.590\n",
      "\n",
      "Interval 439 (219000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "Interval 440 (219500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 474 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 36s 72ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 441 (220000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 442 (220500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 443 (221000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.762\n",
      "\n",
      "Interval 444 (221500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.558\n",
      "\n",
      "Interval 445 (222000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 446 (222500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 447 (223000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.932\n",
      "\n",
      "Interval 448 (223500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.540\n",
      "\n",
      "Interval 449 (224000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 450 (224500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 451 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 65ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 451 (225000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 452 (225500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 453 (226000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.750\n",
      "\n",
      "Interval 454 (226500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.540\n",
      "\n",
      "Interval 455 (227000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 456 (227500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 457 (228000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.978\n",
      "\n",
      "Interval 458 (228500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.646\n",
      "\n",
      "Interval 459 (229000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 460 (229500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 487 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 461 (230000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 462 (230500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.160\n",
      "\n",
      "Interval 463 (231000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.754\n",
      "\n",
      "Interval 464 (231500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.576\n",
      "\n",
      "Interval 465 (232000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 466 (232500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 467 (233000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.976\n",
      "\n",
      "Interval 468 (233500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.600\n",
      "\n",
      "Interval 469 (234000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 470 (234500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 470 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 65ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 471 (235000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 472 (235500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 473 (236000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.814\n",
      "\n",
      "Interval 474 (236500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.546\n",
      "\n",
      "Interval 475 (237000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 476 (237500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 477 (238000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.992\n",
      "\n",
      "Interval 478 (238500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.612\n",
      "\n",
      "Interval 479 (239000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 480 (239500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 475 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 66ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 481 (240000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 482 (240500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 483 (241000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.846\n",
      "\n",
      "Interval 484 (241500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.504\n",
      "\n",
      "Interval 485 (242000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 486 (242500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 487 (243000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.040\n",
      "\n",
      "Interval 488 (243500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.624\n",
      "\n",
      "Interval 489 (244000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 490 (244500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 472 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 491 (245000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.176\n",
      "\n",
      "Interval 492 (245500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 493 (246000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.806\n",
      "\n",
      "Interval 494 (246500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 495 (247000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 496 (247500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 497 (248000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.986\n",
      "\n",
      "Interval 498 (248500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060A: 0s\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.588\n",
      "\n",
      "Interval 499 (249000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 500 (249500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 469 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 501 (250000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 502 (250500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.096\n",
      "\n",
      "Interval 503 (251000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.910\n",
      "\n",
      "Interval 504 (251500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.522\n",
      "\n",
      "Interval 505 (252000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "Interval 506 (252500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 507 (253000 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.052\n",
      "\n",
      "Interval 508 (253500 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.644\n",
      "\n",
      "Interval 509 (254000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0100\n",
      "Interval 510 (254500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 484 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 511 (255000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 512 (255500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.092\n",
      "\n",
      "Interval 513 (256000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.866\n",
      "\n",
      "Interval 514 (256500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 515 (257000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 516 (257500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 517 (258000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.000\n",
      "\n",
      "Interval 518 (258500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.632\n",
      "\n",
      "Interval 519 (259000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 520 (259500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 66ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 521 (260000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 522 (260500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 523 (261000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.846\n",
      "\n",
      "Interval 524 (261500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 525 (262000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 526 (262500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 527 (263000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.042\n",
      "\n",
      "Interval 528 (263500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.650\n",
      "\n",
      "Interval 529 (264000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 530 (264500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 489 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 66ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 531 (265000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 532 (265500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 533 (266000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.842\n",
      "\n",
      "Interval 534 (266500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.542\n",
      "\n",
      "Interval 535 (267000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 536 (267500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 537 (268000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.028\n",
      "\n",
      "Interval 538 (268500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.638\n",
      "\n",
      "Interval 539 (269000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 540 (269500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 499 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 33s 65ms/step - reward: 0.0060\n",
      "Interval 541 (270000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 542 (270500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 543 (271000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.806\n",
      "\n",
      "Interval 544 (271500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 545 (272000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 546 (272500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 547 (273000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.002\n",
      "\n",
      "Interval 548 (273500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.586\n",
      "\n",
      "Interval 549 (274000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 550 (274500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 463 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.156\n",
      "\n",
      "Interval 551 (275000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 552 (275500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 553 (276000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.790\n",
      "\n",
      "Interval 554 (276500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.518\n",
      "\n",
      "Interval 555 (277000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 556 (277500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 557 (278000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.978\n",
      "\n",
      "Interval 558 (278500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.598\n",
      "\n",
      "Interval 559 (279000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 560 (279500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 474 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 561 (280000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.168\n",
      "\n",
      "Interval 562 (280500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 563 (281000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 564 (281500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.532\n",
      "\n",
      "Interval 565 (282000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 566 (282500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 567 (283000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.978\n",
      "\n",
      "Interval 568 (283500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.644\n",
      "\n",
      "Interval 569 (284000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 570 (284500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 493 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.154\n",
      "\n",
      "Interval 571 (285000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 572 (285500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.166\n",
      "\n",
      "Interval 573 (286000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.814\n",
      "\n",
      "Interval 574 (286500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.558\n",
      "\n",
      "Interval 575 (287000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 576 (287500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 577 (288000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 578 (288500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.620\n",
      "\n",
      "Interval 579 (289000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 580 (289500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 473 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 63ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 581 (290000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 582 (290500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 583 (291000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.838\n",
      "\n",
      "Interval 584 (291500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.528\n",
      "\n",
      "Interval 585 (292000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 586 (292500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.098\n",
      "\n",
      "Interval 587 (293000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.004\n",
      "\n",
      "Interval 588 (293500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 589 (294000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 590 (294500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 477 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 64ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.148\n",
      "\n",
      "Interval 591 (295000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 592 (295500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 593 (296000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.786\n",
      "\n",
      "Interval 594 (296500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 595 (297000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "Interval 596 (297500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 597 (298000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.014\n",
      "\n",
      "Interval 598 (298500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.598\n",
      "\n",
      "Interval 599 (299000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 600 (299500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 472 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 32s 64ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 601 (300000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 602 (300500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 603 (301000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.794\n",
      "\n",
      "Interval 604 (301500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.544\n",
      "\n",
      "Interval 605 (302000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 606 (302500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 607 (303000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.020\n",
      "\n",
      "Interval 608 (303500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 609 (304000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 610 (304500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 481 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 611 (305000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 612 (305500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 613 (306000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.906\n",
      "\n",
      "Interval 614 (306500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.524\n",
      "\n",
      "Interval 615 (307000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 616 (307500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 617 (308000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.052\n",
      "\n",
      "Interval 618 (308500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.622\n",
      "\n",
      "Interval 619 (309000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 620 (309500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 488 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 621 (310000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 622 (310500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 623 (311000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.802\n",
      "\n",
      "Interval 624 (311500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.552\n",
      "\n",
      "Interval 625 (312000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 626 (312500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 627 (313000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.950\n",
      "\n",
      "Interval 628 (313500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.578\n",
      "\n",
      "Interval 629 (314000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 630 (314500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 476 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 631 (315000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 632 (315500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.152\n",
      "\n",
      "Interval 633 (316000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.802\n",
      "\n",
      "Interval 634 (316500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 635 (317000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 636 (317500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 637 (318000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.984\n",
      "\n",
      "Interval 638 (318500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.602\n",
      "\n",
      "Interval 639 (319000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 640 (319500 steps performed)\n",
      "493/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 482 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 641 (320000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 642 (320500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 643 (321000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.858\n",
      "\n",
      "Interval 644 (321500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.530\n",
      "\n",
      "Interval 645 (322000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 646 (322500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 647 (323000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.972\n",
      "\n",
      "Interval 648 (323500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 649 (324000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "Interval 650 (324500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0080\n",
      "Evaluated after 444 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 651 (325000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.090\n",
      "\n",
      "Interval 652 (325500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 653 (326000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.830\n",
      "\n",
      "Interval 654 (326500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.522\n",
      "\n",
      "Interval 655 (327000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 656 (327500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 657 (328000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.972\n",
      "\n",
      "Interval 658 (328500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.584\n",
      "\n",
      "Interval 659 (329000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 660 (329500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 460 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.094\n",
      "\n",
      "Interval 661 (330000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 662 (330500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 663 (331000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.894\n",
      "\n",
      "Interval 664 (331500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.544\n",
      "\n",
      "Interval 665 (332000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 666 (332500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 667 (333000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.022\n",
      "\n",
      "Interval 668 (333500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.618\n",
      "\n",
      "Interval 669 (334000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 670 (334500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 465 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 671 (335000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 672 (335500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 673 (336000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.802\n",
      "\n",
      "Interval 674 (336500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.560\n",
      "\n",
      "Interval 675 (337000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 676 (337500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 677 (338000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.016\n",
      "\n",
      "Interval 678 (338500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.636\n",
      "\n",
      "Interval 679 (339000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 680 (339500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 490 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 681 (340000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.090\n",
      "\n",
      "Interval 682 (340500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 683 (341000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.890\n",
      "\n",
      "Interval 684 (341500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 685 (342000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 686 (342500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 687 (343000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.032\n",
      "\n",
      "Interval 688 (343500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.696\n",
      "\n",
      "Interval 689 (344000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 690 (344500 steps performed)\n",
      "493/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 510 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "Interval 691 (345000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.158\n",
      "\n",
      "Interval 692 (345500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 693 (346000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 694 (346500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.520\n",
      "\n",
      "Interval 695 (347000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 696 (347500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 697 (348000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.010\n",
      "\n",
      "Interval 698 (348500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.658\n",
      "\n",
      "Interval 699 (349000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 700 (349500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 488 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.164\n",
      "\n",
      "Interval 701 (350000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.148\n",
      "\n",
      "Interval 702 (350500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 703 (351000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.758\n",
      "\n",
      "Interval 704 (351500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.552\n",
      "\n",
      "Interval 705 (352000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 706 (352500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 707 (353000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.014\n",
      "\n",
      "Interval 708 (353500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.656\n",
      "\n",
      "Interval 709 (354000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 710 (354500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 486 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.160\n",
      "\n",
      "Interval 711 (355000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 712 (355500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 713 (356000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.774\n",
      "\n",
      "Interval 714 (356500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.518\n",
      "\n",
      "Interval 715 (357000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 716 (357500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 717 (358000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.952\n",
      "\n",
      "Interval 718 (358500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 719 (359000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 720 (359500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 457 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 721 (360000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.094\n",
      "\n",
      "Interval 722 (360500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 723 (361000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.830\n",
      "\n",
      "Interval 724 (361500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.558\n",
      "\n",
      "Interval 725 (362000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 726 (362500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 727 (363000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.996\n",
      "\n",
      "Interval 728 (363500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.604\n",
      "\n",
      "Interval 729 (364000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 730 (364500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 462 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 731 (365000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 732 (365500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 733 (366000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.822\n",
      "\n",
      "Interval 734 (366500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.572\n",
      "\n",
      "Interval 735 (367000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 736 (367500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 737 (368000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.022\n",
      "\n",
      "Interval 738 (368500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.634\n",
      "\n",
      "Interval 739 (369000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 740 (369500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 489 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.146\n",
      "\n",
      "Interval 741 (370000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 742 (370500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.102\n",
      "\n",
      "Interval 743 (371000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.842\n",
      "\n",
      "Interval 744 (371500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.536\n",
      "\n",
      "Interval 745 (372000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 746 (372500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.166\n",
      "\n",
      "Interval 747 (373000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.950\n",
      "\n",
      "Interval 748 (373500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 749 (374000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 750 (374500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 462 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 751 (375000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 752 (375500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.126\n",
      "\n",
      "Interval 753 (376000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.834\n",
      "\n",
      "Interval 754 (376500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.518\n",
      "\n",
      "Interval 755 (377000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 756 (377500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 757 (378000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.052\n",
      "\n",
      "Interval 758 (378500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.574\n",
      "\n",
      "Interval 759 (379000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 760 (379500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 461 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 761 (380000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 762 (380500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 763 (381000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.898\n",
      "\n",
      "Interval 764 (381500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.556\n",
      "\n",
      "Interval 765 (382000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 766 (382500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.146\n",
      "\n",
      "Interval 767 (383000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.034\n",
      "\n",
      "Interval 768 (383500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.648\n",
      "\n",
      "Interval 769 (384000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 770 (384500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 498 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 771 (385000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 772 (385500 steps performed)\n",
      "500/500 [==============================] - 3s 6ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 773 (386000 steps performed)\n",
      "500/500 [==============================] - 2s 4ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.902\n",
      "\n",
      "Interval 774 (386500 steps performed)\n",
      "500/500 [==============================] - 2s 3ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.578\n",
      "\n",
      "Interval 775 (387000 steps performed)\n",
      "500/500 [==============================] - 4s 7ms/step - reward: 0.0080\n",
      "Interval 776 (387500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.084\n",
      "\n",
      "Interval 777 (388000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 778 (388500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.674\n",
      "\n",
      "Interval 779 (389000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.550\n",
      "\n",
      "Interval 780 (389500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 520 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "Interval 781 (390000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.082\n",
      "\n",
      "Interval 782 (390500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 783 (391000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.898\n",
      "\n",
      "Interval 784 (391500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.538\n",
      "\n",
      "Interval 785 (392000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 786 (392500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 787 (393000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.016\n",
      "\n",
      "Interval 788 (393500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.650\n",
      "\n",
      "Interval 789 (394000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 790 (394500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 493 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 791 (395000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 792 (395500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 793 (396000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.894\n",
      "\n",
      "Interval 794 (396500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.560\n",
      "\n",
      "Interval 795 (397000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 796 (397500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 797 (398000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.042\n",
      "\n",
      "Interval 798 (398500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.634\n",
      "\n",
      "Interval 799 (399000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 800 (399500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 498 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.136\n",
      "\n",
      "Interval 801 (400000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 802 (400500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 803 (401000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.854\n",
      "\n",
      "Interval 804 (401500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.532\n",
      "\n",
      "Interval 805 (402000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 806 (402500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 807 (403000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.020\n",
      "\n",
      "Interval 808 (403500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.606\n",
      "\n",
      "Interval 809 (404000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 810 (404500 steps performed)\n",
      "493/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 479 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 811 (405000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 812 (405500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 813 (406000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.878\n",
      "\n",
      "Interval 814 (406500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.550\n",
      "\n",
      "Interval 815 (407000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 816 (407500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 817 (408000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.042\n",
      "\n",
      "Interval 818 (408500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.618\n",
      "\n",
      "Interval 819 (409000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 820 (409500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 484 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 821 (410000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.116\n",
      "\n",
      "Interval 822 (410500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 823 (411000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.838\n",
      "\n",
      "Interval 824 (411500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.544\n",
      "\n",
      "Interval 825 (412000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 826 (412500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 827 (413000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.012\n",
      "\n",
      "Interval 828 (413500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.656\n",
      "\n",
      "Interval 829 (414000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 830 (414500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 483 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 831 (415000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 832 (415500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 833 (416000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.786\n",
      "\n",
      "Interval 834 (416500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.550\n",
      "\n",
      "Interval 835 (417000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 836 (417500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 837 (418000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.956\n",
      "\n",
      "Interval 838 (418500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.550\n",
      "\n",
      "Interval 839 (419000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 840 (419500 steps performed)\n",
      "494/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 460 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.148\n",
      "\n",
      "Interval 841 (420000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.142\n",
      "\n",
      "Interval 842 (420500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 843 (421000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.806\n",
      "\n",
      "Interval 844 (421500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.524\n",
      "\n",
      "Interval 845 (422000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 846 (422500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 847 (423000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.994\n",
      "\n",
      "Interval 848 (423500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.632\n",
      "\n",
      "Interval 849 (424000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 850 (424500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 486 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 851 (425000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.098\n",
      "\n",
      "Interval 852 (425500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.094\n",
      "\n",
      "Interval 853 (426000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.898\n",
      "\n",
      "Interval 854 (426500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.532\n",
      "\n",
      "Interval 855 (427000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 856 (427500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 857 (428000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.024\n",
      "\n",
      "Interval 858 (428500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.648\n",
      "\n",
      "Interval 859 (429000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 860 (429500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 488 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.096\n",
      "\n",
      "Interval 861 (430000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.112\n",
      "\n",
      "Interval 862 (430500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 863 (431000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.858\n",
      "\n",
      "Interval 864 (431500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 865 (432000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 866 (432500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 867 (433000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.990\n",
      "\n",
      "Interval 868 (433500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.638\n",
      "\n",
      "Interval 869 (434000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 870 (434500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 482 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 871 (435000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 872 (435500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.108\n",
      "\n",
      "Interval 873 (436000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.810\n",
      "\n",
      "Interval 874 (436500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.542\n",
      "\n",
      "Interval 875 (437000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 876 (437500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 877 (438000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.982\n",
      "\n",
      "Interval 878 (438500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.620\n",
      "\n",
      "Interval 879 (439000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 880 (439500 steps performed)\n",
      "497/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 491 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 881 (440000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 882 (440500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.100\n",
      "\n",
      "Interval 883 (441000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.834\n",
      "\n",
      "Interval 884 (441500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.554\n",
      "\n",
      "Interval 885 (442000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "Interval 886 (442500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 887 (443000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.998\n",
      "\n",
      "Interval 888 (443500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.614\n",
      "\n",
      "Interval 889 (444000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 890 (444500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 474 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 891 (445000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 892 (445500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.130\n",
      "\n",
      "Interval 893 (446000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 894 (446500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.522\n",
      "\n",
      "Interval 895 (447000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 896 (447500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.128\n",
      "\n",
      "Interval 897 (448000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.972\n",
      "\n",
      "Interval 898 (448500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.616\n",
      "\n",
      "Interval 899 (449000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 900 (449500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 480 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.146\n",
      "\n",
      "Interval 901 (450000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.162\n",
      "\n",
      "Interval 902 (450500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 903 (451000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.770\n",
      "\n",
      "Interval 904 (451500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.546\n",
      "\n",
      "Interval 905 (452000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 906 (452500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 907 (453000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.938\n",
      "\n",
      "Interval 908 (453500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.534\n",
      "\n",
      "Interval 909 (454000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "Interval 910 (454500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0081\n",
      "Evaluated after 440 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.124\n",
      "\n",
      "Interval 911 (455000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 912 (455500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.120\n",
      "\n",
      "Interval 913 (456000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.814\n",
      "\n",
      "Interval 914 (456500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 915 (457000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 916 (457500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.154\n",
      "\n",
      "Interval 917 (458000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.988\n",
      "\n",
      "Interval 918 (458500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.568\n",
      "\n",
      "Interval 919 (459000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 920 (459500 steps performed)\n",
      "498/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 464 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 61ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 921 (460000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.114\n",
      "\n",
      "Interval 922 (460500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.134\n",
      "\n",
      "Interval 923 (461000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.818\n",
      "\n",
      "Interval 924 (461500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.556\n",
      "\n",
      "Interval 925 (462000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 926 (462500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 927 (463000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.952\n",
      "\n",
      "Interval 928 (463500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.578\n",
      "\n",
      "Interval 929 (464000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 930 (464500 steps performed)\n",
      "496/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 457 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 31s 62ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.150\n",
      "\n",
      "Interval 931 (465000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.140\n",
      "\n",
      "Interval 932 (465500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.104\n",
      "\n",
      "Interval 933 (466000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.826\n",
      "\n",
      "Interval 934 (466500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.550\n",
      "\n",
      "Interval 935 (467000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 936 (467500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.122\n",
      "\n",
      "Interval 937 (468000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.984\n",
      "\n",
      "Interval 938 (468500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.586\n",
      "\n",
      "Interval 939 (469000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "Interval 940 (469500 steps performed)\n",
      "499/500 [============================>.] - ETA: 0s - reward: 0.0060\n",
      "Evaluated after 464 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.138\n",
      "\n",
      "Interval 941 (470000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.106\n",
      "\n",
      "Interval 942 (470500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 943 (471000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.790\n",
      "\n",
      "Interval 944 (471500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.558\n",
      "\n",
      "Interval 945 (472000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "Interval 946 (472500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.132\n",
      "\n",
      "Interval 947 (473000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.022\n",
      "\n",
      "Interval 948 (473500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.600\n",
      "\n",
      "Interval 949 (474000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "Interval 950 (474500 steps performed)\n",
      "495/500 [============================>.] - ETA: 0s - reward: 0.0061\n",
      "Evaluated after 470 steps — Avg reward: 5.00\n",
      "500/500 [==============================] - 30s 59ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.110\n",
      "\n",
      "Interval 951 (475000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.082\n",
      "\n",
      "Interval 952 (475500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.144\n",
      "\n",
      "Interval 953 (476000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.858\n",
      "\n",
      "Interval 954 (476500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.526\n",
      "\n",
      "Interval 955 (477000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "Interval 956 (477500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.118\n",
      "\n",
      "Interval 957 (478000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 2.030\n",
      "\n",
      "Interval 958 (478500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - ale.lives: 1.624\n",
      "\n",
      "Interval 959 (479000 steps performed)\n",
      "223/500 [============>.................] - ETA: 2s - reward: 0.0135"
     ]
    }
   ],
   "source": [
    "# entrenamiento del agente\n",
    "weights_filename = 'apr_g9_dqn_{}_weights.h5f'.format(env_name)\n",
    "checkpoint_weights_filename = 'apr_g9_dqn_' + env_name + '_weights_{step}.h5f'\n",
    "log_filename = 'apr_g9_dqn_{}_log.json'.format(env_name)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=2500),\n",
    "            FileLogger(log_filename, interval=10),\n",
    "            SaveBestRewardCallback(env, filename='best_model_weights.h5f', test_episodes=5, test_interval=5000)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=10000, log_interval=500, visualize=False)\n",
    "\n",
    "# se graban los pesos finales luego de finalizar el entrenamiento\n",
    "#dqn.save_weights('apr_g9_dqn_{}_weights.h5f'.format(env_name), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OHYryKd1Gb2b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dqn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# test de n episodios para calcular la recompensa final\u001b[39;00m\n\u001b[0;32m      2\u001b[0m weights_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapr_g9_dqn_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_weights.h5f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env_name)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_weights.h5f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m dqn\u001b[38;5;241m.\u001b[39mtest(env, nb_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dqn' is not defined"
     ]
    }
   ],
   "source": [
    "# test de n episodios para calcular la recompensa final\n",
    "weights_filename = 'apr_g9_dqn_{}_weights.h5f'.format(env_name)\n",
    "dqn.load_weights('best_model_weights.h5f')\n",
    "dqn.test(env, nb_episodes=10, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NAlu8b1Gb2b"
   },
   "source": [
    "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANFQiicXK3sO"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_apr_g9",
   "language": "python",
   "name": "env_apr_g9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
