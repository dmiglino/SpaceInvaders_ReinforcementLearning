{
          "cells": [
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "# Actividad - Proyecto práctico (Versión Ultimate)\n",
                                        "\n",
                                        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
                                        "*   Alumno 1: Granizo, Mateo\n",
                                        "*   Alumno 2: Maiolo, Pablo\n",
                                        "*   Alumno 3: Miglino, Diego\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "## **PARTE 1** - Instalación y requisitos previos\n",
                                        "\n",
                                        "> NOTA: Esta versión combina todas las mejoras posibles para maximizar el rendimiento en Space Invaders:\n",
                                        "> - Arquitectura de red optimizada con BatchNormalization y Dropout\n",
                                        "> - Prioritized Experience Replay para aprendizaje más eficiente\n",
                                        "> - Callbacks avanzados para monitoreo y ajuste automático\n",
                                        "> - Hiperparámetros optimizados basados en investigaciones recientes\n",
                                        "\n",
                                        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
                                        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
                                        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
                                        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
                                        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "### 1.1. Preparar enviroment (solo local)\n",
                                        "\n",
                                        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
                                        "1. Instalar Anaconda\n",
                                        "2. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
                                        "\n",
                                        "```\n",
                                        "conda create --name miar_rl python=3.8\n",
                                        "conda activate miar_rl\n",
                                        "cd \"PATH_TO_FOLDER\"\n",
                                        "pip install jupyter\n",
                                        "```\n",
                                        "\n",
                                        "3. Abrir la notebook con *jupyter-notebook*.\n",
                                        "\n",
                                        "```\n",
                                        "jupyter-notebook\n",
                                        "```\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "### 1.2. Localizar entorno de trabajo: Google colab o local"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 5,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "False\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
                                        "mount='/content/gdrive'\n",
                                        "drive_root = mount + \"/My Drive/08_MIAR/actividades/TP_Grupal\"\n",
                                        "mount='./'\n",
                                        "\n",
                                        "try:\n",
                                        "  from google.colab import drive\n",
                                        "  IN_COLAB=True\n",
                                        "except:\n",
                                        "  IN_COLAB=False\n",
                                        "print(IN_COLAB)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "### 1.3. Montar carpeta de datos local (solo Colab)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 6,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Archivos en el directorio: \n",
                                                            "['.git', '.ipynb_checkpoints', 'anaconda_projects', 'apr_g9_dqn_SpaceInvaders-v0_log.json', 'apr_g9_dqn_SpaceInvaders-v0_weights.h5f.data-00000-of-00001', 'apr_g9_dqn_SpaceInvaders-v0_weights.h5f.index', 'APR_Grupo_9.ipynb', 'APR_Grupo_9_callbacks_mini.ipynb', 'APR_Grupo_9_fixed.ipynb', 'APR_Grupo_9_fixed_atari.ipynb', 'APR_Grupo_9_fixed_callbacks.ipynb', 'APR_Grupo_9_fixed_max.ipynb', 'APR_Grupo_9_simple_env.ipynb', 'APR_Grupo_9_ultimate.ipynb', 'APR_Grupo_9_ultimate_combined.ipynb', 'APR_Grupo_9_ultimate_part1.ipynb', 'APR_Grupo_9_ultimate_part2.ipynb', 'APR_Grupo_9_ultimate_part3.ipynb', 'arreglar_atari_roms.bat', 'checkpoint', 'combine.py', 'combine_notebooks.bat', 'combine_notebooks.ps1', 'combine_notebooks.py', 'dqn_CartPole-v1_log.json', 'dqn_CartPole-v1_weights.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights.h5f.index', 'dqn_CartPole-v1_weights_1000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_1000.h5f.index', 'dqn_CartPole-v1_weights_10000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_10000.h5f.index', 'dqn_CartPole-v1_weights_11000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_11000.h5f.index', 'dqn_CartPole-v1_weights_12000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_12000.h5f.index', 'dqn_CartPole-v1_weights_13000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_13000.h5f.index', 'dqn_CartPole-v1_weights_14000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_14000.h5f.index', 'dqn_CartPole-v1_weights_15000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_15000.h5f.index', 'dqn_CartPole-v1_weights_16000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_16000.h5f.index', 'dqn_CartPole-v1_weights_17000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_17000.h5f.index', 'dqn_CartPole-v1_weights_18000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_18000.h5f.index', 'dqn_CartPole-v1_weights_19000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_19000.h5f.index', 'dqn_CartPole-v1_weights_2000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_2000.h5f.index', 'dqn_CartPole-v1_weights_20000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_20000.h5f.index', 'dqn_CartPole-v1_weights_21000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_21000.h5f.index', 'dqn_CartPole-v1_weights_22000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_22000.h5f.index', 'dqn_CartPole-v1_weights_23000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_23000.h5f.index', 'dqn_CartPole-v1_weights_24000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_24000.h5f.index', 'dqn_CartPole-v1_weights_25000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_25000.h5f.index', 'dqn_CartPole-v1_weights_26000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_26000.h5f.index', 'dqn_CartPole-v1_weights_27000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_27000.h5f.index', 'dqn_CartPole-v1_weights_28000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_28000.h5f.index', 'dqn_CartPole-v1_weights_29000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_29000.h5f.index', 'dqn_CartPole-v1_weights_3000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_3000.h5f.index', 'dqn_CartPole-v1_weights_30000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_30000.h5f.index', 'dqn_CartPole-v1_weights_31000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_31000.h5f.index', 'dqn_CartPole-v1_weights_32000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_32000.h5f.index', 'dqn_CartPole-v1_weights_33000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_33000.h5f.index', 'dqn_CartPole-v1_weights_34000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_34000.h5f.index', 'dqn_CartPole-v1_weights_35000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_35000.h5f.index', 'dqn_CartPole-v1_weights_36000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_36000.h5f.index', 'dqn_CartPole-v1_weights_37000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_37000.h5f.index', 'dqn_CartPole-v1_weights_38000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_38000.h5f.index', 'dqn_CartPole-v1_weights_39000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_39000.h5f.index', 'dqn_CartPole-v1_weights_4000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_4000.h5f.index', 'dqn_CartPole-v1_weights_40000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_40000.h5f.index', 'dqn_CartPole-v1_weights_41000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_41000.h5f.index', 'dqn_CartPole-v1_weights_42000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_42000.h5f.index', 'dqn_CartPole-v1_weights_43000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_43000.h5f.index', 'dqn_CartPole-v1_weights_44000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_44000.h5f.index', 'dqn_CartPole-v1_weights_45000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_45000.h5f.index', 'dqn_CartPole-v1_weights_46000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_46000.h5f.index', 'dqn_CartPole-v1_weights_47000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_47000.h5f.index', 'dqn_CartPole-v1_weights_48000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_48000.h5f.index', 'dqn_CartPole-v1_weights_49000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_49000.h5f.index', 'dqn_CartPole-v1_weights_5000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_5000.h5f.index', 'dqn_CartPole-v1_weights_50000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_50000.h5f.index', 'dqn_CartPole-v1_weights_6000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_6000.h5f.index', 'dqn_CartPole-v1_weights_7000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_7000.h5f.index', 'dqn_CartPole-v1_weights_8000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_8000.h5f.index', 'dqn_CartPole-v1_weights_9000.h5f.data-00000-of-00001', 'dqn_CartPole-v1_weights_9000.h5f.index', 'fix_atari_roms.py', 'instalar_atari.bat', 'instalar_atari_conda.bat', 'instalar_gym_basico.bat', 'instalar_gym_basico.py', 'install_atari.py', 'install_atari_cell.py', 'INSTRUCCIONES.txt', 'README.md']\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# Switch to the directory on the Google Drive that you want to use\n",
                                        "import os\n",
                                        "if IN_COLAB:\n",
                                        "  print(\"We're running Colab\")\n",
                                        "\n",
                                        "  if IN_COLAB:\n",
                                        "    # Mount the Google Drive at mount\n",
                                        "    print(\"Colab: mounting Google drive on \", mount)\n",
                                        "\n",
                                        "    drive.mount(mount)\n",
                                        "\n",
                                        "    # Create drive_root if it doesn't exist\n",
                                        "    create_drive_root = True\n",
                                        "    if create_drive_root:\n",
                                        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
                                        "      os.makedirs(drive_root, exist_ok=True)\n",
                                        "\n",
                                        "    # Change to the directory\n",
                                        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
                                        "    %cd $drive_root\n",
                                        "# Verify we're in the correct working directory\n",
                                        "%pwd\n",
                                        "print(\"Archivos en el directorio: \")\n",
                                        "print(os.listdir())"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "### 1.4. Instalar librerías necesarias"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 7,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Requirement already satisfied: gym==0.17.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (0.17.3)Note: you may need to restart the kernel to use updated packages.\n",
                                                            "\n",
                                                            "Requirement already satisfied: scipy in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
                                                            "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.24.4)\n",
                                                            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
                                                            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
                                                            "Requirement already satisfied: future in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
                                                            "Collecting git+https://github.com/openai/atari-py.git\n",
                                                            "  Cloning https://github.com/openai/atari-py.git to c:\\users\\pablo_maiolo\\appdata\\local\\temp\\2\\pip-req-build-xzaa1j_g\n",
                                                            "  Resolved https://github.com/openai/atari-py.git to commit f16dd11124db711ecb1c084014d33e19c3530b36\n",
                                                            "  Preparing metadata (setup.py): started\n",
                                                            "  Preparing metadata (setup.py): finished with status 'done'\n",
                                                            "Requirement already satisfied: numpy in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from atari-py==0.3.0) (1.24.4)\n",
                                                            "Requirement already satisfied: six in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from atari-py==0.3.0) (1.15.0)\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stderr",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/atari-py.git 'C:\\Users\\pablo_maiolo\\AppData\\Local\\Temp\\2\\pip-req-build-xzaa1j_g'\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Requirement already satisfied: pyglet==1.5.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (1.5.0)\n",
                                                            "Requirement already satisfied: future in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyglet==1.5.0) (1.0.0)\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n",
                                                            "Requirement already satisfied: h5py==3.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (3.1.0)\n",
                                                            "Requirement already satisfied: numpy>=1.17.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from h5py==3.1.0) (1.24.4)\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n",
                                                            "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (9.5.0)\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n",
                                                            "Requirement already satisfied: keras-rl2==1.0.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (1.0.5)Note: you may need to restart the kernel to use updated packages.\n",
                                                            "\n",
                                                            "Requirement already satisfied: tensorflow in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from keras-rl2==1.0.5) (2.5.3)\n",
                                                            "Collecting numpy~=1.19.2 (from tensorflow->keras-rl2==1.0.5)\n",
                                                            "  Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
                                                            "Requirement already satisfied: absl-py~=0.10 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.15.0)\n",
                                                            "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
                                                            "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12)\n",
                                                            "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
                                                            "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
                                                            "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.2)\n",
                                                            "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
                                                            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.20.3)\n",
                                                            "Requirement already satisfied: six~=1.15.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.15.0)\n",
                                                            "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.1.0)\n",
                                                            "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (3.7.4.3)\n",
                                                            "Requirement already satisfied: wheel~=0.35 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.44.0)\n",
                                                            "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.12.1)\n",
                                                            "Requirement already satisfied: gast==0.4.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (0.4.0)\n",
                                                            "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.11.2)\n",
                                                            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0)\n",
                                                            "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.5.0.dev2021032900)\n",
                                                            "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (1.34.1)\n",
                                                            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.40.3)\n",
                                                            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.6)\n",
                                                            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.7)\n",
                                                            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.32.4)\n",
                                                            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (75.1.0)\n",
                                                            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
                                                            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (1.8.1)\n",
                                                            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.0.6)\n",
                                                            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (5.5.2)\n",
                                                            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.4.2)\n",
                                                            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (4.9.1)\n",
                                                            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.0.0)\n",
                                                            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (8.5.0)\n",
                                                            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
                                                            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.10)\n",
                                                            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.2.3)\n",
                                                            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
                                                            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
                                                            "Requirement already satisfied: zipp>=3.20 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.21.0)\n",
                                                            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
                                                            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras-rl2==1.0.5) (3.3.1)\n",
                                                            "Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
                                                            "Installing collected packages: numpy\n",
                                                            "  Attempting uninstall: numpy\n",
                                                            "    Found existing installation: numpy 1.24.4\n",
                                                            "    Uninstalling numpy-1.24.4:\n",
                                                            "      Successfully uninstalled numpy-1.24.4\n",
                                                            "Successfully installed numpy-1.19.5\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stderr",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\Lib\\site-packages\\~-mpy'.\n",
                                                            "  You can safely remove it manually.\n",
                                                            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                                                            "matplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires flatbuffers>=23.1.21, but you have flatbuffers 1.12 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.2.4 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.19.5 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.11.2 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires tensorflow-estimator<2.14,>=2.13.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Requirement already satisfied: tensorflow==2.5.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (2.5.3)\n",
                                                            "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.19.5)\n",
                                                            "Requirement already satisfied: absl-py~=0.10 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.15.0)\n",
                                                            "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.6.3)\n",
                                                            "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.12)\n",
                                                            "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.2.0)\n",
                                                            "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.1.0)\n",
                                                            "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.1.2)\n",
                                                            "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.3.0)\n",
                                                            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.20.3)\n",
                                                            "Requirement already satisfied: six~=1.15.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.15.0)\n",
                                                            "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.1.0)\n",
                                                            "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.7.4.3)\n",
                                                            "Requirement already satisfied: wheel~=0.35 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.44.0)\n",
                                                            "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.12.1)\n",
                                                            "Requirement already satisfied: gast==0.4.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.4.0)\n",
                                                            "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (2.11.2)\n",
                                                            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0)\n",
                                                            "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0.dev2021032900)\n",
                                                            "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.34.1)\n",
                                                            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.40.3)\n",
                                                            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.4.6)\n",
                                                            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.7)\n",
                                                            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.32.4)\n",
                                                            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (75.1.0)\n",
                                                            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
                                                            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (1.8.1)\n",
                                                            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.0.6)\n",
                                                            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (5.5.2)\n",
                                                            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.4.2)\n",
                                                            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (4.9.1)\n",
                                                            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (2.0.0)\n",
                                                            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (8.5.0)\n",
                                                            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.4.2)\n",
                                                            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.10)\n",
                                                            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2.2.3)\n",
                                                            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2025.6.15)\n",
                                                            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.3) (2.1.5)\n",
                                                            "Requirement already satisfied: zipp>=3.20 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (3.21.0)\n",
                                                            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
                                                            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (3.3.1)\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n",
                                                            "Requirement already satisfied: matplotlib in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (3.7.5)\n",
                                                            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (1.1.1)\n",
                                                            "Requirement already satisfied: cycler>=0.10 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (0.12.1)\n",
                                                            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (4.57.0)\n",
                                                            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (1.4.7)\n",
                                                            "Collecting numpy<2,>=1.20 (from matplotlib)\n",
                                                            "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
                                                            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (25.0)\n",
                                                            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (9.5.0)\n",
                                                            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (3.1.4)\n",
                                                            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (2.9.0)\n",
                                                            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from matplotlib) (6.4.5)\n",
                                                            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
                                                            "Requirement already satisfied: six>=1.5 in c:\\users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
                                                            "Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
                                                            "Installing collected packages: numpy\n",
                                                            "  Attempting uninstall: numpy\n",
                                                            "    Found existing installation: numpy 1.19.5\n",
                                                            "    Uninstalling numpy-1.19.5:\n",
                                                            "      Successfully uninstalled numpy-1.19.5\n",
                                                            "Successfully installed numpy-1.24.4\n",
                                                            "Note: you may need to restart the kernel to use updated packages.\n"
                                                  ]
                                        },
                                        {
                                                  "name": "stderr",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                                                            "tensorflow 2.5.3 requires numpy~=1.19.2, but you have numpy 1.24.4 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires flatbuffers>=23.1.21, but you have flatbuffers 1.12 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.2.4 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.11.2 which is incompatible.\n",
                                                            "tensorflow-intel 2.13.0 requires tensorflow-estimator<2.14,>=2.13.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# ejecutar solo la primera vez..\n",
                                        "# Instalación mejorada de atari-py usando el fork de OpenAI\n",
                                        "\n",
                                        "if IN_COLAB:\n",
                                        "  %pip install gym==0.17.3\n",
                                        "  %pip install git+https://github.com/openai/atari-py.git\n",
                                        "  %pip install keras-rl2==1.0.5\n",
                                        "  %pip install tensorflow==2.12\n",
                                        "  %pip install matplotlib\n",
                                        "else:\n",
                                        "  %pip install gym==0.17.3\n",
                                        "  %pip install git+https://github.com/openai/atari-py.git\n",
                                        "  %pip install pyglet==1.5.0\n",
                                        "  %pip install h5py==3.1.0\n",
                                        "  %pip install Pillow==9.5.0\n",
                                        "  %pip install keras-rl2==1.0.5\n",
                                        "  %pip install tensorflow==2.5.3\n",
                                        "  %pip install matplotlib"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "## **PARTE 2**. Enunciado\n",
                                        "\n",
                                        "Consideraciones a tener en cuenta:\n",
                                        "\n",
                                        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
                                        "\n",
                                        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
                                        "\n",
                                        "Este proyecto práctico consta de tres partes:\n",
                                        "\n",
                                        "1.   Implementar la red neuronal que se usará en la solución\n",
                                        "2.   Implementar las distintas piezas de la solución DQN\n",
                                        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
                                        "\n",
                                        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
                                        "\n",
                                        "IMPORTANTE:\n",
                                        "\n",
                                        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
                                        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
                                        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
                                        "* Cada alumno deberá de subir la solución de forma individual."
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "---\n",
                                        "## **PARTE 3**. Desarrollo y preguntas"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Importar librerías"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 1,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "ename": "AttributeError",
                                                  "evalue": "module 'numpy' has no attribute 'typeDict'",
                                                  "output_type": "error",
                                                  "traceback": [
                                                            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                                                            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
                                                            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
                                                  ]
                                        },
                                        {
                                                  "name": "stderr",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "c:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:511: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                                                            "  np.object,\n"
                                                  ]
                                        },
                                        {
                                                  "ename": "AttributeError",
                                                  "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                                                  "output_type": "error",
                                                  "traceback": [
                                                            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                                                            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                                                            "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Model\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Activation, Flatten, Convolution2D, Permute, BatchNormalization, Dropout, Input, Concatenate\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, RMSprop\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\__init__.py:46\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:99\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:140\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoShardPolicy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExternalStatePolicy\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:40\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:511\u001b[0m\n\u001b[0;32m    480\u001b[0m     _NP_TO_TF[pdt] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m    481\u001b[0m         _NP_TO_TF[dt] \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m _NP_TO_TF \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m==\u001b[39m pdt()\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    484\u001b[0m TF_VALUE_DTYPES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(_NP_TO_TF\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    487\u001b[0m _TF_TO_NP \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    488\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF:\n\u001b[0;32m    489\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m    490\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT:\n\u001b[0;32m    491\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    492\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE:\n\u001b[0;32m    493\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    494\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32:\n\u001b[0;32m    495\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[0;32m    496\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8:\n\u001b[0;32m    497\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[0;32m    498\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16:\n\u001b[0;32m    499\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[0;32m    500\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32:\n\u001b[0;32m    501\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[0;32m    502\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64:\n\u001b[0;32m    503\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[0;32m    504\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16:\n\u001b[0;32m    505\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[0;32m    506\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8:\n\u001b[0;32m    507\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m# NOTE(touts): For strings we use np.object as it supports variable length\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING:\n\u001b[1;32m--> 511\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject\u001b[49m,\n\u001b[0;32m    512\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64:\n\u001b[0;32m    513\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[0;32m    514\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128:\n\u001b[0;32m    515\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[0;32m    516\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64:\n\u001b[0;32m    517\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m    518\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL:\n\u001b[0;32m    519\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m    520\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8:\n\u001b[0;32m    521\u001b[0m         _np_qint8,\n\u001b[0;32m    522\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8:\n\u001b[0;32m    523\u001b[0m         _np_quint8,\n\u001b[0;32m    524\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16:\n\u001b[0;32m    525\u001b[0m         _np_qint16,\n\u001b[0;32m    526\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16:\n\u001b[0;32m    527\u001b[0m         _np_quint16,\n\u001b[0;32m    528\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32:\n\u001b[0;32m    529\u001b[0m         _np_qint32,\n\u001b[0;32m    530\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16:\n\u001b[0;32m    531\u001b[0m         _np_bfloat16,\n\u001b[0;32m    532\u001b[0m \n\u001b[0;32m    533\u001b[0m     \u001b[38;5;66;03m# Ref types\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF_REF:\n\u001b[0;32m    535\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m    536\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT_REF:\n\u001b[0;32m    537\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    538\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE_REF:\n\u001b[0;32m    539\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    540\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32_REF:\n\u001b[0;32m    541\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[0;32m    542\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32_REF:\n\u001b[0;32m    543\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[0;32m    544\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8_REF:\n\u001b[0;32m    545\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[0;32m    546\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16_REF:\n\u001b[0;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[0;32m    548\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16_REF:\n\u001b[0;32m    549\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[0;32m    550\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8_REF:\n\u001b[0;32m    551\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[0;32m    552\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING_REF:\n\u001b[0;32m    553\u001b[0m         np\u001b[38;5;241m.\u001b[39mobject,\n\u001b[0;32m    554\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64_REF:\n\u001b[0;32m    555\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[0;32m    556\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128_REF:\n\u001b[0;32m    557\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[0;32m    558\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64_REF:\n\u001b[0;32m    559\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m    560\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64_REF:\n\u001b[0;32m    561\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[0;32m    562\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL_REF:\n\u001b[0;32m    563\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[0;32m    564\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8_REF:\n\u001b[0;32m    565\u001b[0m         _np_qint8,\n\u001b[0;32m    566\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8_REF:\n\u001b[0;32m    567\u001b[0m         _np_quint8,\n\u001b[0;32m    568\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16_REF:\n\u001b[0;32m    569\u001b[0m         _np_qint16,\n\u001b[0;32m    570\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16_REF:\n\u001b[0;32m    571\u001b[0m         _np_quint16,\n\u001b[0;32m    572\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32_REF:\n\u001b[0;32m    573\u001b[0m         _np_qint32,\n\u001b[0;32m    574\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16_REF:\n\u001b[0;32m    575\u001b[0m         _np_bfloat16,\n\u001b[0;32m    576\u001b[0m }\n\u001b[0;32m    578\u001b[0m _QUANTIZED_DTYPES_NO_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([qint8, quint8, qint16, quint16, qint32])\n\u001b[0;32m    579\u001b[0m _QUANTIZED_DTYPES_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[0;32m    580\u001b[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
                                                            "File \u001b[1;32mc:\\Users\\pablo_maiolo\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
                                                            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "from __future__ import division\n",
                                        "\n",
                                        "from PIL import Image\n",
                                        "import numpy as np\n",
                                        "import gym\n",
                                        "import matplotlib.pyplot as plt\n",
                                        "import json\n",
                                        "import os\n",
                                        "import random\n",
                                        "from collections import deque\n",
                                        "\n",
                                        "from tensorflow.keras.models import Sequential, Model\n",
                                        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute, BatchNormalization, Dropout, Input, Concatenate\n",
                                        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
                                        "import tensorflow.keras.backend as K\n",
                                        "import tensorflow as tf\n",
                                        "\n",
                                        "from rl.agents.dqn import DQNAgent\n",
                                        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
                                        "from rl.memory import SequentialMemory, Memory\n",
                                        "from rl.core import Processor\n",
                                        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint, Callback"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Configuración base"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "INPUT_SHAPE = (84, 84)\n",
                                        "WINDOW_LENGTH = 4  # Captura 4 frames consecutivos para percibir movimiento\n",
                                        "\n",
                                        "env_name = 'SpaceInvaders-v0'\n",
                                        "env = gym.make(env_name)\n",
                                        "\n",
                                        "np.random.seed(123)\n",
                                        "env.seed(123)\n",
                                        "nb_actions = env.action_space.n\n",
                                        "\n",
                                        "print(\"Numero de acciones disponibles: \" + str(nb_actions))\n",
                                        "print(\"Formato de las observaciones: \" + str(env.observation_space))"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Implementación de Prioritized Experience Replay"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Implementación de Prioritized Experience Replay (PER)\n",
                                        "class PrioritizedMemory(Memory):\n",
                                        "    def __init__(self, limit, alpha=0.6, beta=0.4, beta_increment=0.001, window_length=1):\n",
                                        "        super(PrioritizedMemory, self).__init__()\n",
                                        "        self.limit = limit\n",
                                        "        self.alpha = alpha  # Determina cuánto se usa la prioridad (0 = sin prioridad, 1 = solo prioridad)\n",
                                        "        self.beta = beta    # Importancia del muestreo (0 = sin corrección, 1 = corrección completa)\n",
                                        "        self.beta_increment = beta_increment  # Incremento de beta durante el entrenamiento\n",
                                        "        self.window_length = window_length\n",
                                        "        \n",
                                        "        # Inicializar buffers\n",
                                        "        self.actions = np.zeros(limit, dtype=np.uint8)\n",
                                        "        self.rewards = np.zeros(limit, dtype=np.float32)\n",
                                        "        self.terminals = np.zeros(limit, dtype=np.bool)\n",
                                        "        self.observations = [None] * limit\n",
                                        "        \n",
                                        "        # Variables para PER\n",
                                        "        self.priorities = np.zeros(limit, dtype=np.float32)\n",
                                        "        self.tree = SumTree(limit)\n",
                                        "        self.max_priority = 1.0\n",
                                        "        \n",
                                        "        self.position = 0\n",
                                        "        self.nb_entries = 0\n",
                                        "    \n",
                                        "    def append(self, observation, action, reward, terminal, training=True):\n",
                                        "        super(PrioritizedMemory, self).append(observation, action, reward, terminal, training=training)\n",
                                        "        \n",
                                        "        # Almacenar en buffers\n",
                                        "        self.observations[self.position] = observation\n",
                                        "        self.actions[self.position] = action\n",
                                        "        self.rewards[self.position] = reward\n",
                                        "        self.terminals[self.position] = terminal\n",
                                        "        \n",
                                        "        # Asignar máxima prioridad a nuevas experiencias\n",
                                        "        self.tree.add(self.max_priority, self.position)\n",
                                        "        \n",
                                        "        # Actualizar posición e incrementar entradas\n",
                                        "        self.position = (self.position + 1) % self.limit\n",
                                        "        if self.nb_entries < self.limit:\n",
                                        "            self.nb_entries += 1\n",
                                        "    \n",
                                        "    def _sample_batch_indices(self, batch_size):\n",
                                        "        # Incrementar beta para corrección de importancia\n",
                                        "        self.beta = min(1.0, self.beta + self.beta_increment)\n",
                                        "        \n",
                                        "        # Muestreo basado en prioridad\n",
                                        "        indices = []\n",
                                        "        priorities = []\n",
                                        "        segment = self.tree.total() / batch_size\n",
                                        "        \n",
                                        "        for i in range(batch_size):\n",
                                        "            a = segment * i\n",
                                        "            b = segment * (i + 1)\n",
                                        "            s = random.uniform(a, b)\n",
                                        "            idx, p, _ = self.tree.get(s)\n",
                                        "            indices.append(idx)\n",
                                        "            priorities.append(p)\n",
                                        "        \n",
                                        "        # Calcular pesos para corrección de importancia\n",
                                        "        sampling_probabilities = np.array(priorities) / self.tree.total()\n",
                                        "        is_weights = np.power(self.nb_entries * sampling_probabilities, -self.beta)\n",
                                        "        is_weights /= is_weights.max()  # Normalizar\n",
                                        "        \n",
                                        "        return indices, is_weights\n",
                                        "    \n",
                                        "    def sample(self, batch_size, batch_idxs=None):\n",
                                        "        if batch_idxs is None:\n",
                                        "            batch_idxs, is_weights = self._sample_batch_indices(batch_size)\n",
                                        "        else:\n",
                                        "            is_weights = np.ones((len(batch_idxs),), dtype=np.float32)\n",
                                        "        \n",
                                        "        # Crear batch\n",
                                        "        batch = {}\n",
                                        "        batch['is_weights'] = is_weights\n",
                                        "        batch['batch_idxs'] = batch_idxs\n",
                                        "        \n",
                                        "        # Extraer experiencias\n",
                                        "        batch['observations0'] = []\n",
                                        "        for idx in batch_idxs:\n",
                                        "            batch['observations0'].append(self.observations[idx])\n",
                                        "        \n",
                                        "        batch['actions'] = self.actions[batch_idxs]\n",
                                        "        batch['rewards'] = self.rewards[batch_idxs]\n",
                                        "        batch['terminals'] = self.terminals[batch_idxs]\n",
                                        "        \n",
                                        "        # Obtener observaciones siguientes\n",
                                        "        batch['observations1'] = []\n",
                                        "        for idx in batch_idxs:\n",
                                        "            terminal = self.terminals[idx]\n",
                                        "            if terminal:\n",
                                        "                next_idx = idx\n",
                                        "            else:\n",
                                        "                next_idx = (idx + 1) % self.limit\n",
                                        "            batch['observations1'].append(self.observations[next_idx])\n",
                                        "        \n",
                                        "        return batch\n",
                                        "    \n",
                                        "    def update_priorities(self, batch_idxs, td_errors):\n",
                                        "        # Actualizar prioridades basadas en errores TD\n",
                                        "        for idx, error in zip(batch_idxs, td_errors):\n",
                                        "            priority = (np.abs(error) + 1e-6) ** self.alpha  # Evitar prioridad cero\n",
                                        "            self.tree.update(idx, priority)\n",
                                        "            self.max_priority = max(self.max_priority, priority)\n",
                                        "    \n",
                                        "    def get_config(self):\n",
                                        "        config = {\n",
                                        "            'limit': self.limit,\n",
                                        "            'alpha': self.alpha,\n",
                                        "            'beta': self.beta,\n",
                                        "            'beta_increment': self.beta_increment,\n",
                                        "            'window_length': self.window_length\n",
                                        "        }\n",
                                        "        return config\n",
                                        "\n",
                                        "# Estructura de datos SumTree para PER\n",
                                        "class SumTree:\n",
                                        "    def __init__(self, capacity):\n",
                                        "        self.capacity = capacity\n",
                                        "        self.tree = np.zeros(2 * capacity - 1, dtype=np.float32)\n",
                                        "        self.data = np.zeros(capacity, dtype=np.int32)\n",
                                        "        self.n_entries = 0\n",
                                        "        self.write = 0\n",
                                        "    \n",
                                        "    def _propagate(self, idx, change):\n",
                                        "        # Propagar cambio hacia arriba\n",
                                        "        parent = (idx - 1) // 2\n",
                                        "        self.tree[parent] += change\n",
                                        "        \n",
                                        "        if parent != 0:\n",
                                        "            self._propagate(parent, change)\n",
                                        "    \n",
                                        "    def _retrieve(self, idx, s):\n",
                                        "        left = 2 * idx + 1\n",
                                        "        right = left + 1\n",
                                        "        \n",
                                        "        if left >= len(self.tree):\n",
                                        "            return idx\n",
                                        "        \n",
                                        "        if s <= self.tree[left]:\n",
                                        "            return self._retrieve(left, s)\n",
                                        "        else:\n",
                                        "            return self._retrieve(right, s - self.tree[left])\n",
                                        "    \n",
                                        "    def total(self):\n",
                                        "        return self.tree[0]\n",
                                        "    \n",
                                        "    def add(self, p, data):\n",
                                        "        idx = self.write + self.capacity - 1\n",
                                        "        \n",
                                        "        self.data[self.write] = data\n",
                                        "        self.update(idx, p)\n",
                                        "        \n",
                                        "        self.write = (self.write + 1) % self.capacity\n",
                                        "        if self.n_entries < self.capacity:\n",
                                        "            self.n_entries += 1\n",
                                        "    \n",
                                        "    def update(self, idx, p):\n",
                                        "        change = p - self.tree[idx]\n",
                                        "        \n",
                                        "        self.tree[idx] = p\n",
                                        "        self._propagate(idx, change)\n",
                                        "    \n",
                                        "    def get(self, s):\n",
                                        "        idx = self._retrieve(0, s)\n",
                                        "        dataIdx = idx - self.capacity + 1\n",
                                        "        \n",
                                        "        return (self.data[dataIdx], self.tree[idx], dataIdx)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Implementación de callbacks personalizados"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Callback para guardar pesos después de cada episodio\n",
                                        "class EpisodeCheckpoint(Callback):\n",
                                        "    def __init__(self, filepath, interval=1, verbose=1):\n",
                                        "        super(EpisodeCheckpoint, self).__init__()\n",
                                        "        self.filepath = filepath\n",
                                        "        self.interval = interval\n",
                                        "        self.verbose = verbose\n",
                                        "        self.episode = 0\n",
                                        "        self.best_reward = -np.inf\n",
                                        "        \n",
                                        "    def on_episode_end(self, episode, logs=None):\n",
                                        "        logs = logs or {}\n",
                                        "        self.episode += 1\n",
                                        "        \n",
                                        "        # Guardar pesos cada 'interval' episodios\n",
                                        "        if self.episode % self.interval == 0:\n",
                                        "            filepath = self.filepath.format(episode=self.episode, **logs)\n",
                                        "            if self.verbose > 0:\n",
                                        "                print(f'\\nEpisodio {self.episode}: guardando pesos en {filepath}')\n",
                                        "            self.model.save_weights(filepath, overwrite=True)\n",
                                        "        \n",
                                        "        # Guardar los mejores pesos basados en la recompensa\n",
                                        "        if logs.get('episode_reward', -np.inf) > self.best_reward:\n",
                                        "            self.best_reward = logs.get('episode_reward')\n",
                                        "            best_filepath = self.filepath.format(episode='best')\n",
                                        "            if self.verbose > 0:\n",
                                        "                print(f'\\nNueva mejor recompensa: {self.best_reward:.2f}, guardando en {best_filepath}')\n",
                                        "            self.model.save_weights(best_filepath, overwrite=True)\n",
                                        "\n",
                                        "# Callback para visualizar el progreso del entrenamiento\n",
                                        "class TrainingVisualization(Callback):\n",
                                        "    def __init__(self, log_file, plot_interval=5):\n",
                                        "        super(TrainingVisualization, self).__init__()\n",
                                        "        self.log_file = log_file\n",
                                        "        self.plot_interval = plot_interval\n",
                                        "        self.episode_rewards = []\n",
                                        "        self.episode_losses = []\n",
                                        "        self.episode_maes = []\n",
                                        "        self.episode = 0\n",
                                        "        self.moving_avg_rewards = []\n",
                                        "        self.window_size = 10  # Tamaño de la ventana para promedio móvil\n",
                                        "        \n",
                                        "    def on_episode_end(self, episode, logs=None):\n",
                                        "        logs = logs or {}\n",
                                        "        self.episode += 1\n",
                                        "        \n",
                                        "        # Guardar métricas\n",
                                        "        reward = logs.get('episode_reward', 0)\n",
                                        "        self.episode_rewards.append(reward)\n",
                                        "        self.episode_losses.append(logs.get('loss', 0))\n",
                                        "        self.episode_maes.append(logs.get('mae', 0))\n",
                                        "        \n",
                                        "        # Calcular promedio móvil de recompensas\n",
                                        "        if len(self.episode_rewards) >= self.window_size:\n",
                                        "            avg_reward = np.mean(self.episode_rewards[-self.window_size:])\n",
                                        "        else:\n",
                                        "            avg_reward = np.mean(self.episode_rewards)\n",
                                        "        self.moving_avg_rewards.append(avg_reward)\n",
                                        "        \n",
                                        "        # Guardar datos en archivo JSON\n",
                                        "        data = {\n",
                                        "            'episode_rewards': self.episode_rewards,\n",
                                        "            'episode_losses': self.episode_losses,\n",
                                        "            'episode_maes': self.episode_maes,\n",
                                        "            'moving_avg_rewards': self.moving_avg_rewards\n",
                                        "        }\n",
                                        "        with open(self.log_file, 'w') as f:\n",
                                        "            json.dump(data, f)\n",
                                        "        \n",
                                        "        # Visualizar progreso cada plot_interval episodios\n",
                                        "        if self.episode % self.plot_interval == 0:\n",
                                        "            self.visualize_training()\n",
                                        "    \n",
                                        "    def visualize_training(self):\n",
                                        "        plt.figure(figsize=(15, 10))\n",
                                        "        \n",
                                        "        # Gráfico de recompensas\n",
                                        "        plt.subplot(2, 2, 1)\n",
                                        "        plt.plot(self.episode_rewards)\n",
                                        "        plt.title('Recompensas por episodio')\n",
                                        "        plt.xlabel('Episodio')\n",
                                        "        plt.ylabel('Recompensa')\n",
                                        "        \n",
                                        "        # Gráfico de promedio móvil de recompensas\n",
                                        "        plt.subplot(2, 2, 2)\n",
                                        "        plt.plot(self.moving_avg_rewards)\n",
                                        "        plt.title(f'Promedio móvil de recompensas (ventana={self.window_size})')\n",
                                        "        plt.xlabel('Episodio')\n",
                                        "        plt.ylabel('Recompensa promedio')\n",
                                        "        \n",
                                        "        # Gráfico de pérdidas\n",
                                        "        plt.subplot(2, 2, 3)\n",
                                        "        plt.plot(self.episode_losses)\n",
                                        "        plt.title('Pérdida por episodio')\n",
                                        "        plt.xlabel('Episodio')\n",
                                        "        plt.ylabel('Pérdida')\n",
                                        "        \n",
                                        "        # Gráfico de MAE\n",
                                        "        plt.subplot(2, 2, 4)\n",
                                        "        plt.plot(self.episode_maes)\n",
                                        "        plt.title('MAE por episodio')\n",
                                        "        plt.xlabel('Episodio')\n",
                                        "        plt.ylabel('MAE')\n",
                                        "        \n",
                                        "        plt.tight_layout()\n",
                                        "        plt.show()\n",
                                        "\n",
                                        "# Callback para ajustar la tasa de aprendizaje durante el entrenamiento\n",
                                        "class LearningRateScheduler(Callback):\n",
                                        "    def __init__(self, initial_lr=0.00025, min_lr=0.00001, decay_factor=0.5, decay_episodes=50):\n",
                                        "        super(LearningRateScheduler, self).__init__()\n",
                                        "        self.initial_lr = initial_lr\n",
                                        "        self.min_lr = min_lr\n",
                                        "        self.decay_factor = decay_factor\n",
                                        "        self.decay_episodes = decay_episodes\n",
                                        "        self.episode = 0\n",
                                        "        \n",
                                        "    def on_episode_end(self, episode, logs=None):\n",
                                        "        logs = logs or {}\n",
                                        "        self.episode += 1\n",
                                        "        \n",
                                        "        # Ajustar tasa de aprendizaje cada decay_episodes episodios\n",
                                        "        if self.episode % self.decay_episodes == 0:\n",
                                        "            old_lr = K.get_value(self.model.optimizer.lr)\n",
                                        "            new_lr = max(old_lr * self.decay_factor, self.min_lr)  # No bajar más del mínimo\n",
                                        "            K.set_value(self.model.optimizer.lr, new_lr)\n",
                                        "            print(f'\\nEpisodio {self.episode}: tasa de aprendizaje ajustada de {old_lr:.6f} a {new_lr:.6f}')"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Implementación del procesador de observaciones"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "class AtariProcessor(Processor):\n",
                                        "    def process_observation(self, observation):\n",
                                        "        assert observation.ndim == 3  # (height, width, channel)\n",
                                        "        img = Image.fromarray(observation)\n",
                                        "        img = img.resize(INPUT_SHAPE).convert('L')  # Convertir a escala de grises\n",
                                        "        processed_observation = np.array(img)\n",
                                        "        assert processed_observation.shape == INPUT_SHAPE\n",
                                        "        return processed_observation.astype('uint8')  # Guardar como uint8 para ahorrar memoria\n",
                                        "\n",
                                        "    def process_state_batch(self, batch):\n",
                                        "        processed_batch = batch.astype('float32') / 255.  # Normalizar a [0, 1]\n",
                                        "        return processed_batch\n",
                                        "\n",
                                        "    def process_reward(self, reward):\n",
                                        "        return np.clip(reward, -1., 1.)  # Recortar recompensas para estabilizar el aprendizaje"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### 1. Implementación de la red neuronal"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Modelo mejorado con arquitectura más profunda y técnicas avanzadas\n",
                                        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
                                        "model = Sequential()\n",
                                        "\n",
                                        "if K.image_data_format() == 'channels_last':\n",
                                        "    # (width, height, channels)\n",
                                        "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
                                        "elif K.image_data_format() == 'channels_first':\n",
                                        "    # (channels, width, height)\n",
                                        "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
                                        "else:\n",
                                        "    raise RuntimeError('Unknown image_dim_ordering.')\n",
                                        "\n",
                                        "# Primera capa convolucional\n",
                                        "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
                                        "model.add(BatchNormalization())  # Normalización por lotes para estabilizar el entrenamiento\n",
                                        "model.add(Activation('relu'))\n",
                                        "\n",
                                        "# Segunda capa convolucional\n",
                                        "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
                                        "model.add(BatchNormalization())\n",
                                        "model.add(Activation('relu'))\n",
                                        "\n",
                                        "# Tercera capa convolucional\n",
                                        "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
                                        "model.add(BatchNormalization())\n",
                                        "model.add(Activation('relu'))\n",
                                        "\n",
                                        "# Cuarta capa convolucional adicional para mayor capacidad\n",
                                        "model.add(Convolution2D(128, (3, 3), strides=(1, 1)))\n",
                                        "model.add(BatchNormalization())\n",
                                        "model.add(Activation('relu'))\n",
                                        "\n",
                                        "# Aplanar para capas densas\n",
                                        "model.add(Flatten())\n",
                                        "\n",
                                        "# Primera capa densa\n",
                                        "model.add(Dense(512))\n",
                                        "model.add(BatchNormalization())\n",
                                        "model.add(Activation('relu'))\n",
                                        "model.add(Dropout(0.2))  # Dropout para evitar sobreajuste\n",
                                        "\n",
                                        "# Segunda capa densa\n",
                                        "model.add(Dense(256))\n",
                                        "model.add(BatchNormalization())\n",
                                        "model.add(Activation('relu'))\n",
                                        "\n",
                                        "# Capa de salida\n",
                                        "model.add(Dense(nb_actions))\n",
                                        "model.add(Activation('linear'))\n",
                                        "\n",
                                        "print(model.summary())"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### 2. Implementación de la solución DQN con Prioritized Experience Replay"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Configuración de la memoria con Prioritized Experience Replay\n",
                                        "memory = PrioritizedMemory(limit=100000,  # Memoria grande para almacenar más experiencias\n",
                                        "                          alpha=0.6,      # Prioridad basada en errores TD\n",
                                        "                          beta=0.4,       # Corrección de importancia del muestreo\n",
                                        "                          beta_increment=0.0005,  # Incremento gradual de beta\n",
                                        "                          window_length=WINDOW_LENGTH)\n",
                                        "\n",
                                        "# Procesador para las observaciones\n",
                                        "processor = AtariProcessor()\n",
                                        "\n",
                                        "# Política de exploración con decaimiento lineal\n",
                                        "# Comenzamos con exploración completa (1.0) y reducimos gradualmente a 0.05\n",
                                        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
                                        "                              value_max=1.0, value_min=0.05, value_test=0.01,\n",
                                        "                              nb_steps=150000)  # Decaimiento más lento para mejor exploración\n",
                                        "\n",
                                        "# Definición del agente DQN\n",
                                        "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
                                        "               memory=memory, processor=processor,\n",
                                        "               nb_steps_warmup=10000,  # Más pasos de calentamiento para llenar la memoria\n",
                                        "               gamma=0.99,  # Factor de descuento alto para valorar recompensas futuras\n",
                                        "               target_model_update=10000,  # Actualización menos frecuente de la red objetivo\n",
                                        "               train_interval=4,  # Entrenar cada 4 pasos para estabilidad\n",
                                        "               delta_clip=1.0)  # Recortar el error delta para evitar explosiones de gradiente\n",
                                        "\n",
                                        "# Compilación del agente con optimizador RMSprop (mejor para DQN en Atari)\n",
                                        "dqn.compile(RMSprop(learning_rate=0.00025, rho=0.95, epsilon=0.01), metrics=['mae'])"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Configuración de callbacks y entrenamiento"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Configuración de callbacks\n",
                                        "weights_filename = 'dqn_ultimate_{}_weights.h5f'.format(env_name)\n",
                                        "checkpoint_weights_filename = 'dqn_ultimate_' + env_name + '_weights_episode_{episode}.h5f'\n",
                                        "log_filename = 'dqn_ultimate_{}_log.json'.format(env_name)\n",
                                        "visualization_log = 'dqn_ultimate_{}_visualization.json'.format(env_name)\n",
                                        "\n",
                                        "# Crear directorio para checkpoints si no existe\n",
                                        "checkpoint_dir = 'checkpoints'\n",
                                        "if not os.path.exists(checkpoint_dir):\n",
                                        "    os.makedirs(checkpoint_dir)\n",
                                        "\n",
                                        "# Callbacks personalizados\n",
                                        "callbacks = [\n",
                                        "    # Guardar pesos cada 5 episodios\n",
                                        "    EpisodeCheckpoint(os.path.join(checkpoint_dir, checkpoint_weights_filename), interval=5),\n",
                                        "    \n",
                                        "    # Visualizar progreso cada 5 episodios\n",
                                        "    TrainingVisualization(visualization_log, plot_interval=5),\n",
                                        "    \n",
                                        "    # Ajustar tasa de aprendizaje cada 50 episodios\n",
                                        "    LearningRateScheduler(initial_lr=0.00025, min_lr=0.00001, decay_factor=0.5, decay_episodes=50),\n",
                                        "    \n",
                                        "    # Logger estándar\n",
                                        "    FileLogger(log_filename, interval=100)\n",
                                        "]"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Entrenamiento del agente\n",
                                        "dqn.fit(env, callbacks=callbacks, nb_steps=250000, log_interval=1000, visualize=False)\n",
                                        "\n",
                                        "# Guardar pesos finales\n",
                                        "dqn.save_weights(weights_filename, overwrite=True)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Visualización de resultados del entrenamiento"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Cargar y visualizar datos de entrenamiento\n",
                                        "if os.path.exists(visualization_log):\n",
                                        "    with open(visualization_log, 'r') as f:\n",
                                        "        data = json.load(f)\n",
                                        "    \n",
                                        "    plt.figure(figsize=(15, 10))\n",
                                        "    \n",
                                        "    # Gráfico de recompensas\n",
                                        "    plt.subplot(2, 2, 1)\n",
                                        "    plt.plot(data['episode_rewards'])\n",
                                        "    plt.title('Recompensas por episodio')\n",
                                        "    plt.xlabel('Episodio')\n",
                                        "    plt.ylabel('Recompensa')\n",
                                        "    \n",
                                        "    # Gráfico de promedio móvil de recompensas\n",
                                        "    plt.subplot(2, 2, 2)\n",
                                        "    plt.plot(data['moving_avg_rewards'])\n",
                                        "    plt.title('Promedio móvil de recompensas')\n",
                                        "    plt.xlabel('Episodio')\n",
                                        "    plt.ylabel('Recompensa promedio')\n",
                                        "    \n",
                                        "    # Gráfico de pérdidas\n",
                                        "    plt.subplot(2, 2, 3)\n",
                                        "    plt.plot(data['episode_losses'])\n",
                                        "    plt.title('Pérdida por episodio')\n",
                                        "    plt.xlabel('Episodio')\n",
                                        "    plt.ylabel('Pérdida')\n",
                                        "    \n",
                                        "    # Gráfico de MAE\n",
                                        "    plt.subplot(2, 2, 4)\n",
                                        "    plt.plot(data['episode_maes'])\n",
                                        "    plt.title('MAE por episodio')\n",
                                        "    plt.xlabel('Episodio')\n",
                                        "    plt.ylabel('MAE')\n",
                                        "    \n",
                                        "    plt.tight_layout()\n",
                                        "    plt.show()"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### Test del agente entrenado"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Probar con los mejores pesos\n",
                                        "best_weights_filename = os.path.join(checkpoint_dir, 'dqn_ultimate_' + env_name + '_weights_episode_best.h5f')\n",
                                        "if os.path.exists(best_weights_filename):\n",
                                        "    print(f\"Cargando los mejores pesos desde: {best_weights_filename}\")\n",
                                        "    dqn.load_weights(best_weights_filename)\n",
                                        "else:\n",
                                        "    print(f\"No se encontraron los mejores pesos, usando los pesos finales: {weights_filename}\")\n",
                                        "    dqn.load_weights(weights_filename)\n",
                                        "\n",
                                        "# Test de n episodios para calcular la recompensa final\n",
                                        "dqn.test(env, nb_episodes=10, visualize=True)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "#### 3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "metadata": {},
                              "source": [
                                        "### Justificación de los parámetros seleccionados\n",
                                        "\n",
                                        "En esta implementación optimizada para máximo rendimiento, se han incorporado numerosas mejoras basadas en investigaciones recientes en aprendizaje por refuerzo profundo:\n",
                                        "\n",
                                        "1. **Prioritized Experience Replay (PER)**:\n",
                                        "   - Implementación completa de PER que prioriza experiencias con mayor error TD.\n",
                                        "   - Parámetros α=0.6 y β=0.4 inicialmente, con incremento gradual de β hasta 1.0.\n",
                                        "   - Esta técnica permite un aprendizaje más eficiente al muestrear con mayor frecuencia experiencias más informativas.\n",
                                        "\n",
                                        "2. **Arquitectura de red neuronal mejorada**:\n",
                                        "   - Red convolucional profunda con 4 capas convolucionales (vs 3 en implementaciones estándar).\n",
                                        "   - Capa adicional de 128 filtros para capturar patrones más complejos.\n",
                                        "   - BatchNormalization después de cada capa para estabilizar y acelerar el entrenamiento.\n",
                                        "   - Dos capas densas (512 y 256 neuronas) para mayor capacidad de representación.\n",
                                        "   - Dropout (20%) para prevenir el sobreajuste.\n",
                                        "\n",
                                        "3. **Memoria de experiencia mucho más grande**:\n",
                                        "   - Aumentada a 100,000 experiencias para mantener un historial más amplio.\n",
                                        "   - Permite al agente aprender de una variedad mucho mayor de situaciones.\n",
                                        "\n",
                                        "4. **Exploración más efectiva**:\n",
                                        "   - Decaimiento de epsilon más lento (150,000 pasos).\n",
                                        "   - Valor mínimo de epsilon reducido a 0.05 para mantener algo de exploración incluso al final.\n",
                                        "   - Valor de test reducido a 0.01 para evaluación más determinista.\n",
                                        "\n",
                                        "5. **Entrenamiento extenso**:\n",
                                        "   - 250,000 pasos de entrenamiento para permitir un aprendizaje profundo.\n",
                                        "   - 10,000 pasos de calentamiento para llenar adecuadamente la memoria antes de comenzar el aprendizaje.\n",
                                        "\n",
                                        "6. **Callbacks personalizados**:\n",
                                        "   - EpisodeCheckpoint: Guarda pesos cada 5 episodios y mantiene los mejores pesos basados en recompensa.\n",
                                        "   - TrainingVisualization: Visualiza el progreso del entrenamiento con gráficos detallados.\n",
                                        "   - LearningRateScheduler: Ajusta automáticamente la tasa de aprendizaje para evitar estancamiento.\n",
                                        "\n",
                                        "7. **Optimizador RMSprop optimizado**:\n",
                                        "   - Parámetros específicos (learning_rate=0.00025, rho=0.95) que han demostrado mejor rendimiento en DQN para juegos Atari.\n",
                                        "\n",
                                        "### Resultados esperados\n",
                                        "\n",
                                        "Con estas mejoras, esperamos que el agente logre una puntuación significativamente superior al requisito mínimo de 20 puntos. Basándonos en implementaciones similares en la literatura científica, este modelo optimizado debería ser capaz de alcanzar puntuaciones en el rango de 500-1500 puntos en Space Invaders, lo que representa un rendimiento muy competente.\n",
                                        "\n",
                                        "Las mejoras implementadas siguen las mejores prácticas establecidas en los artículos seminales sobre DQN y sus variantes, particularmente:\n",
                                        "\n",
                                        "1. **Prioritized Experience Replay** (Schaul et al., 2015)\n",
                                        "2. **Deep Q-Network con mejoras arquitectónicas** (Mnih et al., 2015)\n",
                                        "3. **Técnicas de estabilización del entrenamiento** como BatchNormalization y Dropout\n",
                                        "4. **Ajuste dinámico de hiperparámetros** durante el entrenamiento\n",
                                        "\n",
                                        "La combinación de estas técnicas avanzadas debería permitir al agente desarrollar estrategias sofisticadas para maximizar su puntuación en Space Invaders, superando ampliamente los requisitos mínimos del proyecto."
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "miar_rl",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.8.20"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 4
}
